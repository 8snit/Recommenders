{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Normalization test of split and metrics functions \n",
    "\n",
    "In this notebook we check the consistency of split and metrics function. We first check this using an artificial dataset and then using the movielens 100k data used in the recommender tests.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.6 |Anaconda custom (64-bit)| (default, Jun 28 2018, 11:07:29) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "Pandas version: 0.23.4\n"
     ]
    }
   ],
   "source": [
    "# set the environment path to find Recommenders\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_random_split, python_stratified_split\n",
    "from reco_utils.dataset.numpy_splitters import numpy_stratified_split\n",
    "from reco_utils.dataset.sparse import AffinityMatrix\n",
    "\n",
    "from reco_utils.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "## 1 Artificial dataset \n",
    "\n",
    "For debugging purpose it is useful to generate random sparse matrices. The function `affinity_matrix()` a random rating matrix with a specified degree of sparsness. Realistic user/affinity matrices show a high degree of sparsness;  for example, the sparsness of the movielens dataset is $\\ge 90$%, depending on the particular chosen data size, e.g. movielens 100k $\\simeq 93$%, movielens 1m $\\simeq 95$% etc...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinity_matrix(users, items, ratings, spars):\n",
    "\n",
    "    '''\n",
    "    Generate a random user/item affinity matrix. By increasing the likehood of 0 elements we simulate \n",
    "    a typical recommeding situation where the input matrix is highly sparse. \n",
    "    \n",
    "    Args: \n",
    "        users (int): number of users (rows).\n",
    "        items (int): number of items (columns).\n",
    "        ratings (int): rating scale, e.g. 5 meaning rates are from 1 to 5.\n",
    "        spars: probablity of obtaining zero. This roughly correponds to the sparsness. \n",
    "               of the generated matrix. If spars = 0 then the affinity matrix is dense. \n",
    "    \n",
    "    Returns: \n",
    "        X (np array, int): sparse user/affinity matrix \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    np.random.seed(123)\n",
    "\n",
    "    s= [(1-spars)/5]*5 #uniform probability for the 5 ratings\n",
    "    s.append(spars) \n",
    "    P= s[::-1] \n",
    "    \n",
    "    # generates the user/item affinity matrix. Ratings are from 1 to 5, with 0s denoting unrated items\n",
    "    X= np.random.choice(ratings+1, (users,items), p = P)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0,\n",
       "        2, 0, 0, 5, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 3,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 2, 0, 0, 0, 0, 0, 5, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 5, 3, 0,\n",
       "        0, 0, 3, 5, 0, 0, 1, 0, 0, 0, 0, 2, 5, 0, 0, 0, 0, 0, 0, 0, 4, 0,\n",
       "        0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 4, 0, 0, 0, 0,\n",
       "        2, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 4, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 5,\n",
       "        0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 5, 0, 0, 0, 0, 5, 0,\n",
       "        0, 0, 5, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 5, 0, 2, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 5, 2, 0, 4, 0, 2, 0, 4,\n",
       "        0, 4, 1, 2, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0,\n",
       "        4, 0, 0, 0, 0, 2, 0, 4, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 4, 3, 0, 0,\n",
       "        0, 0, 0, 0, 3, 1],\n",
       "       [0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 4, 0,\n",
       "        0, 0, 0, 0, 0, 2],\n",
       "       [0, 0, 4, 0, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "        4, 1, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 2, 0,\n",
       "        0, 3, 2, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 5, 3, 0,\n",
       "        0, 5, 3, 3, 0, 0],\n",
       "       [0, 0, 2, 0, 3, 0, 0, 0, 3, 0, 1, 2, 4, 0, 0, 0, 0, 4, 0, 0, 0, 0,\n",
       "        5, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 2],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 5, 0, 3, 0, 2, 2, 4, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 4, 3, 0, 5, 0,\n",
       "        0, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 5, 0, 0, 0, 4, 4, 0,\n",
       "        0, 0, 1, 2, 0, 0],\n",
       "       [0, 0, 0, 4, 1, 0, 0, 0, 0, 1, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0,\n",
       "        4, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 4, 3, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 2, 5, 0, 0, 2],\n",
       "       [4, 0, 0, 0, 2, 0, 0, 5, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1,\n",
       "        2, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 3, 4, 3, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 3, 0, 0, 4, 0,\n",
       "        0, 2, 1, 0, 0, 0, 5, 1, 3, 0, 0, 0, 0, 4, 4, 2, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 2, 4, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        2, 5, 0, 0, 0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0,\n",
       "        5, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 4, 0, 0, 0, 0, 2, 0, 5, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 2, 0, 0],\n",
       "       [3, 0, 0, 0, 5, 0, 0, 4, 0, 2, 0, 0, 0, 0, 2, 0, 3, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 3, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate the random sparse matrix. In this example we choose a ~80% sparsness \n",
    "X = affinity_matrix(users=20,items=50, ratings= 5, spars= 0.8)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the sparsness of the dataset#\n",
    "\n",
    "zero = (X == 0).sum()  # number of unrated items\n",
    "total = X.shape[0] * X.shape[1]  # number of elements in the matrix\n",
    "sparsness = zero / total * 100  # Percentage of zeros in the matrix\n",
    "\n",
    "sparsness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  7, 12,  9, 10, 12, 12,  7, 12, 11, 10,  8, 14, 13, 11, 12, 11,\n",
       "        8,  9,  4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of ratings per user\n",
    "rated = np.sum(X != 0, axis=1)\n",
    "rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total number of rated items \n",
    "total_rated = rated.sum()\n",
    "total_rated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to simulate the recommendation task, we split this dataset into train and test set and evaluate precision@k on the test set alone. This introduces additional sparsness in the data and we check how this affect the normalization of the the @k results. Below, we compare two different split strategies, the first is the **global** split of `python_random_split`and the second is the **local** split `of numpy_stratified_split`. In order to apply the former splitter we first need to map X to a dataframe representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_to_df(X):\n",
    "\n",
    "        \"\"\"\n",
    "        Map the user/affinity matrix to a pd dataframe\n",
    "\n",
    "        \"\"\"\n",
    "        m, n = X.shape #obtain the matrix dimensions: m = #users, n=#items \n",
    "\n",
    "        userids = []\n",
    "\n",
    "        for i in range(1, m+1):\n",
    "            userids.extend([i]*n)\n",
    "\n",
    "\n",
    "        itemids = [i for i in range(1, n+1)]*m\n",
    "        ratings = np.reshape(X, -1)\n",
    "\n",
    "        #create dataframe\n",
    "        results = pd.DataFrame.from_dict(\n",
    "                        {\n",
    "                            'user': userids,\n",
    "                            'item': itemids,\n",
    "                            'rating': ratings,\n",
    "                         }\n",
    "                    )\n",
    "\n",
    "        #here we eliminate the missing ratings to obtain a standard form of the df as that of real dataframe.\n",
    "        results = results[results.rating !=0]\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user  item  rating\n",
       "6      1     7       5\n",
       "21     1    22       2\n",
       "37     1    38       3\n",
       "38     1    39       4\n",
       "44     1    45       2\n",
       "47     1    48       5\n",
       "51     2     2       1\n",
       "58     2     9       2\n",
       "64     2    15       2\n",
       "71     2    22       3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a pandas df \n",
    "X_df = sparse_to_df(X)\n",
    "X_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Splitting \n",
    "\n",
    "Splitting data in an unsupervised setting generally works differently than in the supervised one. \n",
    "\n",
    "Let us first consider a typical supervised learning problem, for example a binary classification problem. We are given a matrix $X^{\\mu}_i$, where $\\mu \\in [1, m]$ is the example index and $i \\in [1,n]$ is the feature index. We are also given a ground truth vector $y^{\\mu}$. The matrix $\\hat{X}$ is generally dense and we want to cut a certain percentage `t` of examples for the training set and `(1-t)` for the test set. In this case $Xtr^{\\mu}_i$ contains the **same** number of features (columns) but different examples (rows) and we split $y^{\\mu}$ accordingly. \n",
    "\n",
    "In the unspervised case, no ground truth vector is provided. In the recommendation case, the user/item affinity matrix contains the ratings as training examples; the only way to verify if the recommendation is correct is to cut part of the ratings for the test set: the ratings are in this case the examples. For the same user we can then verify if the prediction is correct or not by comparing to the test set. Due to the unequal number of ratings per user, we need to make sure that each user contributes the same number of train/test examples. \n",
    "\n",
    "\n",
    "Since the matrix is sparse and inhomogenous,  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Python Random splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data using the random split \n",
    "Xtr_random, Xtst_random = python_random_split(X_df, ratio = 0.75, seed= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user  item  rating\n",
       "767    16    18       3\n",
       "165     4    16       1\n",
       "331     7    32       3\n",
       "183     4    34       1\n",
       "128     3    29       1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtst_random.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global % of rated items in the train set 74.74747474747475\n",
      "global % of rated items in the test set 25.252525252525253\n"
     ]
    }
   ],
   "source": [
    "print( 'global % of rated items in the train set', (len(Xtr_random.rating)/total_rated)*100 )\n",
    "print( 'global % of rated items in the test set', (len(Xtst_random.rating)/total_rated)*100 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check now the per-user percentage of train/tes set example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user\n",
       "1     2.525253\n",
       "2     3.535354\n",
       "3     4.040404\n",
       "4     3.030303\n",
       "5     3.535354\n",
       "6     5.050505\n",
       "7     5.555556\n",
       "8     2.525253\n",
       "9     4.545455\n",
       "10    4.040404\n",
       "11    4.040404\n",
       "12    2.020202\n",
       "13    6.060606\n",
       "14    5.555556\n",
       "15    5.050505\n",
       "16    3.030303\n",
       "17    3.030303\n",
       "18    2.020202\n",
       "19    3.535354\n",
       "20    2.020202\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user % of training example \n",
    "(Xtr_random.groupby(by= 'user').rating.count()/total_rated)*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user\n",
       "1     0.505051\n",
       "3     2.020202\n",
       "4     1.515152\n",
       "5     1.515152\n",
       "6     1.010101\n",
       "7     0.505051\n",
       "8     1.010101\n",
       "9     1.515152\n",
       "10    1.515152\n",
       "11    1.010101\n",
       "12    2.020202\n",
       "13    1.010101\n",
       "14    1.010101\n",
       "15    0.505051\n",
       "16    3.030303\n",
       "17    2.525253\n",
       "18    2.020202\n",
       "19    1.010101\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user % of test example \n",
    "(Xtst_random.groupby(by= 'user').rating.count()/total_rated)*100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can identify the following problems: \n",
    "\n",
    "1. each user, both in train and test set, contributes a different number of examples. \n",
    "2. the per user train/test ratio is unbalanced, e.g. user1 in train test contributes 5 times more than in test but for user3 it is only 2 times.   \n",
    "3. the test set misses two users with no apparent reason (2 and 20). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Python Stratified splitter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data using the random split \n",
    "Xtr_strat, Xtst_strat = python_stratified_split(X_df, ratio = 0.75, seed= 123, col_user ='user', col_item= 'item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user  item  rating\n",
       "37      1    38       3\n",
       "47      1    48       5\n",
       "85      2    36       2\n",
       "91      2    42       5\n",
       "125     3    26       5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtst_strat.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global % of rated items in the train set 74.74747474747475\n",
      "global % of rated items in the test set 25.252525252525253\n"
     ]
    }
   ],
   "source": [
    "print( 'global % of rated items in the train set', (len(Xtr_strat.rating)/total_rated)*100 )\n",
    "print( 'global % of rated items in the test set', (len(Xtst_strat.rating)/total_rated)*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user\n",
       "1     2.020202\n",
       "2     2.525253\n",
       "3     4.545455\n",
       "4     3.535354\n",
       "5     4.040404\n",
       "6     4.545455\n",
       "7     4.545455\n",
       "8     2.525253\n",
       "9     4.545455\n",
       "10    4.040404\n",
       "11    4.040404\n",
       "12    3.030303\n",
       "13    5.050505\n",
       "14    5.050505\n",
       "15    4.040404\n",
       "16    4.545455\n",
       "17    4.040404\n",
       "18    3.030303\n",
       "19    3.535354\n",
       "20    1.515152\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user % of training example \n",
    "(Xtr_strat.groupby(by= 'user').rating.count()/total_rated)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the sum of the above percentages is 74.74% as it should be. So both the `random` and the `stratified` split breaks split the original dataset into non equal percentages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user\n",
       "1     1.010101\n",
       "2     1.010101\n",
       "3     1.515152\n",
       "4     1.010101\n",
       "5     1.010101\n",
       "6     1.515152\n",
       "7     1.515152\n",
       "8     1.010101\n",
       "9     1.515152\n",
       "10    1.515152\n",
       "11    1.010101\n",
       "12    1.010101\n",
       "13    2.020202\n",
       "14    1.515152\n",
       "15    1.515152\n",
       "16    1.515152\n",
       "17    1.515152\n",
       "18    1.010101\n",
       "19    1.010101\n",
       "20    0.505051\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user % of test example \n",
    "(Xtst_strat.groupby(by= 'user').rating.count()/total_rated)*100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the number of users is the same in both train and test set but again the percentage of per user example is not constant nor is the split ratio between train and test set. This clearly has effects on the statistical analysis of the model performance (the evalaluation metrics). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Numpy stratified split \n",
    "\n",
    "In this case the data are split by keeping a per-user, constant percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_np, Xtst_np = numpy_stratified_split(X, ratio = 0.75, seed= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of rated elements in the train/test set \n",
    "Xtr_rated = np.sum(Xtr_np != 0, axis=1)  # number of rated items in the train set\n",
    "Xtst_rated = np.sum(Xtst_np != 0, axis=1)  # number of rated items in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global % of rated items in the train set 74.74747474747475\n",
      "global % of rated items in the test set 25.252525252525253\n"
     ]
    }
   ],
   "source": [
    "print( 'global % of rated items in the train set', (Xtr_rated.sum() / total_rated)*100 )\n",
    "print( 'global % of rated items in the test set', (Xtst_rated.sum() / total_rated)*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66666667, 0.71428571, 0.75      , 0.77777778, 0.8       ,\n",
       "       0.75      , 0.75      , 0.71428571, 0.75      , 0.72727273,\n",
       "       0.8       , 0.75      , 0.71428571, 0.76923077, 0.72727273,\n",
       "       0.75      , 0.72727273, 0.75      , 0.77777778, 0.75      ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user percentage of training examples \n",
    "Xtr_rated/rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.28571429, 0.25      , 0.22222222, 0.2       ,\n",
       "       0.25      , 0.25      , 0.28571429, 0.25      , 0.27272727,\n",
       "       0.2       , 0.25      , 0.28571429, 0.23076923, 0.27272727,\n",
       "       0.25      , 0.27272727, 0.25      , 0.22222222, 0.25      ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user percentage of test examples \n",
    "Xtst_rated/rated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also in this case the per user, training percentage are not exactly 75% but much closer to it than the previous case. The reason for these fluctuations is due to rounding errors and in principle and can be improven."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Evaluation \n",
    "\n",
    "We now consider the evaluation metrics and their normalization. As an example, we consider precision@k and rmse. As a first step, we are interested in determining the maximum achievable precision for precision@k; conventionally, this is set to one to denote a perfect score, in agreement with the normalization of the corresponding distribution. The definition is\n",
    "$$ p_k = \\frac{1}{m} \\sum_{\\mu=1}^m \\frac{1}{k} \\sum_{i =1}^{min(k, |D_i|)} I(X_p = X_{tst})^{\\mu}_i$$,\n",
    "where $I()$ is known as an indicator \"function\", even thought mathematically is a distribution. An example of this class is the Dirac delta function $\\delta(X_p - X_{tst})$. The above definition has the (known) problem of not being normalized to 1 if the number of test set elements is less than k, as it can be see explictly from the above equation. Below we show that this is often the case when working with sparse matrices.   \n",
    "\n",
    "The first thing to do is to simulate a recommendation of 10 elements, where "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user\n",
       "1     1\n",
       "3     4\n",
       "4     3\n",
       "5     3\n",
       "6     2\n",
       "7     1\n",
       "8     2\n",
       "9     3\n",
       "10    3\n",
       "11    2\n",
       "12    4\n",
       "13    2\n",
       "14    2\n",
       "15    1\n",
       "16    6\n",
       "17    5\n",
       "18    4\n",
       "19    2\n",
       "Name: item, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtst_random.groupby(by='user')['item'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user  item  rating\n",
       "128     3    29       1\n",
       "125     3    26       5\n",
       "149     3    50       1\n",
       "142     3    43       4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtst_random[Xtst_random.user==3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Movielens 100k dataset\n",
    "\n",
    "Below we apply the above analysis on the movielens 100k dataset. The size of the dataset enhanches many of the features found above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating  timestamp\n",
       "0     196      242       3  881250949\n",
       "1     186      302       3  891717742\n",
       "2      22      377       1  878887116\n",
       "3     244       51       2  880606923\n",
       "4     166      346       1  886397596"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select Movielens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'\n",
    "\n",
    "data = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=['userID','movieID','rating','timestamp']\n",
    ")\n",
    "\n",
    "# Convert to 32-bit in order to reduce memory consumption \n",
    "data.loc[:, 'rating'] = data['rating'].astype(np.int32) \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_rated_ml = data.rating.count()\n",
    "total_rated_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nusers= len(data.userID.unique())\n",
    "Nusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nitems= len(data.movieID.unique())\n",
    "Nitems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. Random Splitter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data using the random split \n",
    "Ztr_random, Ztst_random = python_random_split(data, ratio = 0.75, seed= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42083</th>\n",
       "      <td>600</td>\n",
       "      <td>651</td>\n",
       "      <td>4</td>\n",
       "      <td>888451492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71825</th>\n",
       "      <td>607</td>\n",
       "      <td>494</td>\n",
       "      <td>5</td>\n",
       "      <td>883879556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99535</th>\n",
       "      <td>875</td>\n",
       "      <td>1103</td>\n",
       "      <td>5</td>\n",
       "      <td>876465144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47879</th>\n",
       "      <td>648</td>\n",
       "      <td>238</td>\n",
       "      <td>3</td>\n",
       "      <td>882213535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36734</th>\n",
       "      <td>113</td>\n",
       "      <td>273</td>\n",
       "      <td>4</td>\n",
       "      <td>875935609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userID  movieID  rating  timestamp\n",
       "42083     600      651       4  888451492\n",
       "71825     607      494       5  883879556\n",
       "99535     875     1103       5  876465144\n",
       "47879     648      238       3  882213535\n",
       "36734     113      273       4  875935609"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ztst_random.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global % of rated items in the train set 75.0\n",
      "global % of rated items in the test set 25.0\n"
     ]
    }
   ],
   "source": [
    "print( 'global % of rated items in the train set', (len(Ztr_random.rating)/total_rated_ml)*100 )\n",
    "print( 'global % of rated items in the test set', (len(Ztst_random.rating)/total_rated_ml)*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userID\n",
       "1      0.203\n",
       "2      0.045\n",
       "3      0.037\n",
       "4      0.018\n",
       "5      0.133\n",
       "6      0.161\n",
       "7      0.303\n",
       "8      0.046\n",
       "9      0.014\n",
       "10     0.148\n",
       "11     0.130\n",
       "12     0.039\n",
       "13     0.454\n",
       "14     0.077\n",
       "15     0.080\n",
       "16     0.111\n",
       "17     0.018\n",
       "18     0.197\n",
       "19     0.015\n",
       "20     0.036\n",
       "21     0.136\n",
       "22     0.096\n",
       "23     0.105\n",
       "24     0.055\n",
       "25     0.066\n",
       "26     0.085\n",
       "27     0.017\n",
       "28     0.058\n",
       "29     0.025\n",
       "30     0.027\n",
       "       ...  \n",
       "914    0.018\n",
       "915    0.017\n",
       "916    0.237\n",
       "917    0.022\n",
       "918    0.073\n",
       "919    0.163\n",
       "920    0.017\n",
       "921    0.078\n",
       "922    0.100\n",
       "923    0.058\n",
       "924    0.060\n",
       "925    0.023\n",
       "926    0.015\n",
       "927    0.086\n",
       "928    0.022\n",
       "929    0.035\n",
       "930    0.048\n",
       "931    0.047\n",
       "932    0.173\n",
       "933    0.129\n",
       "934    0.136\n",
       "935    0.033\n",
       "936    0.116\n",
       "937    0.031\n",
       "938    0.080\n",
       "939    0.045\n",
       "940    0.084\n",
       "941    0.019\n",
       "942    0.059\n",
       "943    0.126\n",
       "Name: rating, Length: 943, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user % of training example \n",
    "(Ztr_random.groupby(by= 'userID').rating.count()/total_rated_ml)*100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, most users get a % of training examples $\\ll 1$%. We can check this explictly by printing the % of users getting more than 1% of the training examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.738069989395548"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( ((Ztr_random.groupby(by= 'userID').rating.count()/total_rated_ml)*100  >= 0.1).sum()/Nusers )*100  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userID\n",
       "1      0.069\n",
       "2      0.017\n",
       "3      0.017\n",
       "4      0.006\n",
       "5      0.042\n",
       "6      0.050\n",
       "7      0.100\n",
       "8      0.013\n",
       "9      0.008\n",
       "10     0.036\n",
       "11     0.051\n",
       "12     0.012\n",
       "13     0.182\n",
       "14     0.021\n",
       "15     0.024\n",
       "16     0.029\n",
       "17     0.010\n",
       "18     0.080\n",
       "19     0.005\n",
       "20     0.012\n",
       "21     0.043\n",
       "22     0.032\n",
       "23     0.046\n",
       "24     0.013\n",
       "25     0.012\n",
       "26     0.022\n",
       "27     0.008\n",
       "28     0.021\n",
       "29     0.009\n",
       "30     0.016\n",
       "       ...  \n",
       "914    0.005\n",
       "915    0.009\n",
       "916    0.080\n",
       "917    0.013\n",
       "918    0.030\n",
       "919    0.054\n",
       "920    0.009\n",
       "921    0.032\n",
       "922    0.027\n",
       "923    0.016\n",
       "924    0.022\n",
       "925    0.009\n",
       "926    0.005\n",
       "927    0.034\n",
       "928    0.010\n",
       "929    0.014\n",
       "930    0.015\n",
       "931    0.014\n",
       "932    0.068\n",
       "933    0.055\n",
       "934    0.038\n",
       "935    0.006\n",
       "936    0.026\n",
       "937    0.009\n",
       "938    0.028\n",
       "939    0.004\n",
       "940    0.023\n",
       "941    0.003\n",
       "942    0.020\n",
       "943    0.042\n",
       "Name: rating, Length: 943, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user % of test example \n",
    "(Ztst_random.groupby(by= 'userID').rating.count()/total_rated_ml)*100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also in this case, we can evaluate the % of test examples $\\ge 1$%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.014846235418876"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( ((Ztst_random.groupby(by= 'userID').rating.count()/total_rated_ml)*100  >= 0.1).sum()/Nusers )*100  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are interested in evaluating the effect of the splitter on the @k metrics with $k=10$, we can find the fraction of users in the test set having at least 10 test examples. As explained in the previous section, this also defines the maximum achievable precision of the recommender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7073170731707317"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( ( (Ztst_random.groupby(by= 'userID').rating.count() ) >= 10 ).sum()/Nusers )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average number of per user rated elements 26.511134676564158\n",
      "standard deviation 25.9943225934054\n"
     ]
    }
   ],
   "source": [
    "print('average number of per user rated elements', np.mean((Ztst_random.groupby(by= 'userID').rating.count() )) )\n",
    "print('standard deviation', np.std((Ztst_random.groupby(by= 'userID').rating.count() )) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Python Stratified Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data using the random split \n",
    "Ztr_strat, Ztst_strat = python_stratified_split(data, ratio = 0.75, seed= 123, col_user ='userID', col_item= 'itemID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15764</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>5</td>\n",
       "      <td>874965677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14792</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>878542845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8737</th>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "      <td>4</td>\n",
       "      <td>888732908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62069</th>\n",
       "      <td>1</td>\n",
       "      <td>191</td>\n",
       "      <td>5</td>\n",
       "      <td>875072956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25721</th>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>3</td>\n",
       "      <td>878542608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userID  movieID  rating  timestamp\n",
       "15764       1      196       5  874965677\n",
       "14792       1      103       1  878542845\n",
       "8737        1      209       4  888732908\n",
       "62069       1      191       5  875072956\n",
       "25721       1      141       3  878542608"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ztst_strat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global % of rated items in the train set 74.992\n",
      "global % of rated items in the test set 25.008000000000003\n"
     ]
    }
   ],
   "source": [
    "print( 'global % of rated items in the train set', (len(Ztr_strat.rating)/total_rated_ml)*100 )\n",
    "print( 'global % of rated items in the test set', (len(Ztst_strat.rating)/total_rated_ml)*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userID\n",
       "1      0.204\n",
       "2      0.046\n",
       "3      0.040\n",
       "4      0.018\n",
       "5      0.131\n",
       "6      0.158\n",
       "7      0.302\n",
       "8      0.044\n",
       "9      0.016\n",
       "10     0.138\n",
       "11     0.136\n",
       "12     0.038\n",
       "13     0.477\n",
       "14     0.074\n",
       "15     0.078\n",
       "16     0.105\n",
       "17     0.021\n",
       "18     0.208\n",
       "19     0.015\n",
       "20     0.036\n",
       "21     0.134\n",
       "22     0.096\n",
       "23     0.113\n",
       "24     0.051\n",
       "25     0.058\n",
       "26     0.080\n",
       "27     0.019\n",
       "28     0.059\n",
       "29     0.026\n",
       "30     0.032\n",
       "       ...  \n",
       "914    0.017\n",
       "915    0.020\n",
       "916    0.238\n",
       "917    0.026\n",
       "918    0.077\n",
       "919    0.163\n",
       "920    0.020\n",
       "921    0.082\n",
       "922    0.095\n",
       "923    0.056\n",
       "924    0.062\n",
       "925    0.024\n",
       "926    0.015\n",
       "927    0.090\n",
       "928    0.024\n",
       "929    0.037\n",
       "930    0.047\n",
       "931    0.046\n",
       "932    0.181\n",
       "933    0.138\n",
       "934    0.130\n",
       "935    0.029\n",
       "936    0.106\n",
       "937    0.030\n",
       "938    0.081\n",
       "939    0.037\n",
       "940    0.080\n",
       "941    0.016\n",
       "942    0.059\n",
       "943    0.126\n",
       "Name: rating, Length: 943, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user % of training example \n",
    "(Ztr_strat.groupby(by= 'userID').rating.count()/total_rated_ml)*100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the % of users getting more than 1% of the training examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.056203605514312"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( ((Ztr_strat.groupby(by= 'userID').rating.count()/total_rated_ml)*100  >= 0.1).sum()/Nusers )*100  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userID\n",
       "1      0.068\n",
       "2      0.016\n",
       "3      0.014\n",
       "4      0.006\n",
       "5      0.044\n",
       "6      0.053\n",
       "7      0.101\n",
       "8      0.015\n",
       "9      0.006\n",
       "10     0.046\n",
       "11     0.045\n",
       "12     0.013\n",
       "13     0.159\n",
       "14     0.024\n",
       "15     0.026\n",
       "16     0.035\n",
       "17     0.007\n",
       "18     0.069\n",
       "19     0.005\n",
       "20     0.012\n",
       "21     0.045\n",
       "22     0.032\n",
       "23     0.038\n",
       "24     0.017\n",
       "25     0.020\n",
       "26     0.027\n",
       "27     0.006\n",
       "28     0.020\n",
       "29     0.008\n",
       "30     0.011\n",
       "       ...  \n",
       "914    0.006\n",
       "915    0.006\n",
       "916    0.079\n",
       "917    0.009\n",
       "918    0.026\n",
       "919    0.054\n",
       "920    0.006\n",
       "921    0.028\n",
       "922    0.032\n",
       "923    0.018\n",
       "924    0.020\n",
       "925    0.008\n",
       "926    0.005\n",
       "927    0.030\n",
       "928    0.008\n",
       "929    0.012\n",
       "930    0.016\n",
       "931    0.015\n",
       "932    0.060\n",
       "933    0.046\n",
       "934    0.044\n",
       "935    0.010\n",
       "936    0.036\n",
       "937    0.010\n",
       "938    0.027\n",
       "939    0.012\n",
       "940    0.027\n",
       "941    0.006\n",
       "942    0.020\n",
       "943    0.042\n",
       "Name: rating, Length: 943, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user % of test example \n",
    "(Ztst_strat.groupby(by= 'userID').rating.count()/total_rated_ml)*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8027571580063628"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( ((Ztst_strat.groupby(by= 'userID').rating.count()/total_rated_ml)*100  >= 0.1).sum()/Nusers )*100  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7020148462354189"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( ( (Ztst_strat.groupby(by= 'userID').rating.count() ) >= 10 ).sum()/Nusers )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average number of per user rated elements 26.51961823966066\n",
      "standard deviation 25.218943440036778\n"
     ]
    }
   ],
   "source": [
    "print('average number of per user rated elements', np.mean((Ztst_strat.groupby(by= 'userID').rating.count() )) )\n",
    "print('standard deviation', np.std((Ztst_strat.groupby(by= 'userID').rating.count() )) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Numpy stratified split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to use standard names across the analysis \n",
    "header = {\n",
    "        \"col_user\": \"userID\",\n",
    "        \"col_item\": \"movieID\",\n",
    "        \"col_rating\": \"rating\",\n",
    "    }\n",
    "\n",
    "#instantiate the splitter \n",
    "am = AffinityMatrix(DF = data, **header)\n",
    "\n",
    "#obtain the sparse matrix \n",
    "Z = am.gen_affinity_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ztr_np, Ztst_np = numpy_stratified_split(Z, ratio=0.75, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of rated elements in the train/test set \n",
    "Ztr_np_rated = np.sum(Ztr_np != 0, axis=1)  # number of rated items in the train set\n",
    "Ztst_np_rated = np.sum(Ztst_np != 0, axis=1)  # number of rated items in the test set\n",
    "\n",
    "#number of ratings per user\n",
    "Zrated = np.sum(Z != 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global % of rated items in the train set 74.992\n",
      "global % of rated items in the test set 25.008000000000003\n"
     ]
    }
   ],
   "source": [
    "print( 'global % of rated items in the train set', (Ztr_np_rated.sum() / total_rated_ml)*100 )\n",
    "print( 'global % of rated items in the test set', (Ztst_np_rated.sum() / total_rated_ml)*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75      , 0.74193548, 0.74074074, 0.75      , 0.74857143,\n",
       "       0.74881517, 0.74937965, 0.74576271, 0.72727273, 0.75      ,\n",
       "       0.75138122, 0.74509804, 0.75      , 0.75510204, 0.75      ,\n",
       "       0.75      , 0.75      , 0.75090253, 0.75      , 0.75      ,\n",
       "       0.74860335, 0.75      , 0.74834437, 0.75      , 0.74358974,\n",
       "       0.74766355, 0.76      , 0.74683544, 0.76470588, 0.74418605,\n",
       "       0.75      , 0.75609756, 0.75      , 0.75      , 0.76      ,\n",
       "       0.75      , 0.75438596, 0.75206612, 0.72727273, 0.74285714,\n",
       "       0.75      , 0.74863388, 0.75113122, 0.74834437, 0.75      ,\n",
       "       0.74074074, 0.76      , 0.75757576, 0.74883721, 0.75      ,\n",
       "       0.73913043, 0.75      , 0.75      , 0.75384615, 0.76190476,\n",
       "       0.7486631 , 0.75471698, 0.75324675, 0.7486911 , 0.75      ,\n",
       "       0.76190476, 0.75      , 0.75268817, 0.75      , 0.75      ,\n",
       "       0.73684211, 0.73333333, 0.76470588, 0.75384615, 0.7480916 ,\n",
       "       0.73684211, 0.75182482, 0.75757576, 0.74358974, 0.74683544,\n",
       "       0.75609756, 0.75      , 0.76190476, 0.74545455, 0.75862069,\n",
       "       0.75862069, 0.75      , 0.7483871 , 0.75      , 0.75      ,\n",
       "       0.73913043, 0.74881517, 0.76190476, 0.75      , 0.75      ,\n",
       "       0.75510204, 0.75      , 0.75      , 0.75      , 0.74820144,\n",
       "       0.75      , 0.74603175, 0.74074074, 0.75      , 0.74576271,\n",
       "       0.74626866, 0.75      , 0.75862069, 0.74774775, 0.73913043,\n",
       "       0.75      , 0.72727273, 0.75757576, 0.75213675, 0.7518797 ,\n",
       "       0.75      , 0.73913043, 0.74509804, 0.75      , 0.75      ,\n",
       "       0.74825175, 0.74418605, 0.74647887, 0.75138122, 0.76923077,\n",
       "       0.75675676, 0.75409836, 0.74074074, 0.75      , 0.74725275,\n",
       "       0.75555556, 0.73913043, 0.75      , 0.73333333, 0.75070822,\n",
       "       0.73333333, 0.72727273, 0.76923077, 0.76      , 0.74545455,\n",
       "       0.74285714, 0.74468085, 0.74509804, 0.75      , 0.76190476,\n",
       "       0.74766355, 0.75757576, 0.75      , 0.74757282, 0.75      ,\n",
       "       0.75862069, 0.75      , 0.75384615, 0.75      , 0.75      ,\n",
       "       0.74918567, 0.75471698, 0.73913043, 0.74509804, 0.72727273,\n",
       "       0.75675676, 0.74509804, 0.75144509, 0.74766355, 0.75      ,\n",
       "       0.75862069, 0.76190476, 0.73913043, 0.74603175, 0.73333333,\n",
       "       0.75      , 0.75362319, 0.75362319, 0.75675676, 0.72727273,\n",
       "       0.75      , 0.74074074, 0.74418605, 0.75141243, 0.73684211,\n",
       "       0.74603175, 0.74782609, 0.75091575, 0.76190476, 0.74603175,\n",
       "       0.74942529, 0.75      , 0.75471698, 0.74900398, 0.75      ,\n",
       "       0.75      , 0.75      , 0.75      , 0.7486631 , 0.74576271,\n",
       "       0.74074074, 0.74285714, 0.75206612, 0.75081967, 0.75      ,\n",
       "       0.74358974, 0.74576271, 0.75138122, 0.75      , 0.75      ,\n",
       "       0.75129534, 0.75      , 0.74418605, 0.76190476, 0.72727273,\n",
       "       0.75      , 0.74782609, 0.75757576, 0.75757576, 0.75      ,\n",
       "       0.75675676, 0.76      , 0.74603175, 0.75      , 0.75268817,\n",
       "       0.7480916 , 0.75      , 0.75471698, 0.75      , 0.72727273,\n",
       "       0.75342466, 0.74935401, 0.75238095, 0.75177305, 0.74074074,\n",
       "       0.76      , 0.75862069, 0.76190476, 0.73333333, 0.7518797 ,\n",
       "       0.76190476, 0.75268817, 0.74545455, 0.75      , 0.74468085,\n",
       "       0.75      , 0.75      , 0.75862069, 0.74842767, 0.75      ,\n",
       "       0.73913043, 0.75      , 0.75308642, 0.74789916, 0.72727273,\n",
       "       0.74871795, 0.76923077, 0.75      , 0.7515528 , 0.75409836,\n",
       "       0.75324675, 0.76190476, 0.75257732, 0.74842767, 0.74698795,\n",
       "       0.74879227, 0.75438596, 0.73913043, 0.73913043, 0.75      ,\n",
       "       0.74074074, 0.75      , 0.74796748, 0.75      , 0.73913043,\n",
       "       0.73913043, 0.75135135, 0.75      , 0.74922601, 0.75362319,\n",
       "       0.74820144, 0.74509804, 0.72727273, 0.74647887, 0.74736842,\n",
       "       0.74903475, 0.74074074, 0.73913043, 0.75115207, 0.75193798,\n",
       "       0.76923077, 0.72727273, 0.75471698, 0.74468085, 0.75      ,\n",
       "       0.75      , 0.74193548, 0.74666667, 0.74074074, 0.74666667,\n",
       "       0.75      , 0.75      , 0.75      , 0.74666667, 0.75      ,\n",
       "       0.74829932, 0.75      , 0.7480315 , 0.75      , 0.75      ,\n",
       "       0.74909091, 0.76190476, 0.75      , 0.76923077, 0.74774775,\n",
       "       0.75      , 0.75      , 0.75062972, 0.75      , 0.76190476,\n",
       "       0.74829932, 0.74887892, 0.7480916 , 0.75102041, 0.74712644,\n",
       "       0.74666667, 0.72727273, 0.74712644, 0.73913043, 0.75324675,\n",
       "       0.752     , 0.74509804, 0.75280899, 0.75757576, 0.74647887,\n",
       "       0.7486631 , 0.75      , 0.74911661, 0.75384615, 0.74829932,\n",
       "       0.74285714, 0.74863388, 0.76923077, 0.75075075, 0.72727273,\n",
       "       0.75384615, 0.76470588, 0.74666667, 0.7480315 , 0.75      ,\n",
       "       0.76190476, 0.75124378, 0.75105485, 0.74736842, 0.75      ,\n",
       "       0.75129534, 0.74874372, 0.75862069, 0.75609756, 0.76      ,\n",
       "       0.75      , 0.76190476, 0.76      , 0.75107296, 0.76923077,\n",
       "       0.75      , 0.75      , 0.74418605, 0.74074074, 0.74509804,\n",
       "       0.75206612, 0.76      , 0.74919614, 0.75      , 0.75862069,\n",
       "       0.75757576, 0.75862069, 0.75555556, 0.72727273, 0.74666667,\n",
       "       0.74509804, 0.75757576, 0.75107296, 0.75182482, 0.75      ,\n",
       "       0.73333333, 0.75757576, 0.74933333, 0.75      , 0.75308642,\n",
       "       0.7480315 , 0.75471698, 0.74647887, 0.72727273, 0.75088968,\n",
       "       0.73913043, 0.75      , 0.75      , 0.74907749, 0.74193548,\n",
       "       0.75206612, 0.74774775, 0.75      , 0.75167785, 0.75438596,\n",
       "       0.74074074, 0.74509804, 0.75      , 0.7492163 , 0.72727273,\n",
       "       0.75163399, 0.75      , 0.76      , 0.75      , 0.75033921,\n",
       "       0.74853801, 0.75221239, 0.74074074, 0.74876847, 0.75      ,\n",
       "       0.75862069, 0.74509804, 0.76      , 0.76      , 0.75      ,\n",
       "       0.7505071 , 0.75068493, 0.75      , 0.75      , 0.75      ,\n",
       "       0.74193548, 0.75257732, 0.75      , 0.75      , 0.75      ,\n",
       "       0.75247525, 0.74193548, 0.74545455, 0.74879227, 0.75384615,\n",
       "       0.76190476, 0.74193548, 0.75609756, 0.75      , 0.74934037,\n",
       "       0.75172414, 0.74904943, 0.75757576, 0.74193548, 0.74509804,\n",
       "       0.75      , 0.74825175, 0.75      , 0.75      , 0.74814815,\n",
       "       0.75      , 0.74820144, 0.73684211, 0.74666667, 0.75      ,\n",
       "       0.75510204, 0.74757282, 0.75      , 0.75      , 0.75132275,\n",
       "       0.75115207, 0.75090253, 0.74863388, 0.74576271, 0.75      ,\n",
       "       0.73913043, 0.75757576, 0.7518797 , 0.75471698, 0.75      ,\n",
       "       0.75247525, 0.75      , 0.74825175, 0.74418605, 0.75438596,\n",
       "       0.74193548, 0.74904943, 0.74285714, 0.74923547, 0.75      ,\n",
       "       0.74698795, 0.74285714, 0.75221239, 0.75247525, 0.75      ,\n",
       "       0.75      , 0.76923077, 0.74576271, 0.74820144, 0.76923077,\n",
       "       0.75132275, 0.74891775, 0.75324675, 0.75229358, 0.75438596,\n",
       "       0.75757576, 0.74545455, 0.74814815, 0.74468085, 0.75117371,\n",
       "       0.75193798, 0.74910394, 0.75167785, 0.74509804, 0.75111111,\n",
       "       0.75342466, 0.75675676, 0.75      , 0.74900398, 0.75      ,\n",
       "       0.75206612, 0.75862069, 0.74712644, 0.75757576, 0.73333333,\n",
       "       0.75      , 0.76190476, 0.72727273, 0.75257732, 0.75      ,\n",
       "       0.76190476, 0.75675676, 0.75342466, 0.75510204, 0.73913043,\n",
       "       0.74666667, 0.73333333, 0.75      , 0.75163399, 0.74074074,\n",
       "       0.75      , 0.75182482, 0.75471698, 0.74418605, 0.75555556,\n",
       "       0.73333333, 0.75182482, 0.75      , 0.75      , 0.75229358,\n",
       "       0.74846626, 0.75102041, 0.75308642, 0.75      , 0.74603175,\n",
       "       0.7518797 , 0.74814815, 0.75126904, 0.74193548, 0.75308642,\n",
       "       0.74576271, 0.73913043, 0.7483871 , 0.76      , 0.75      ,\n",
       "       0.74850299, 0.75      , 0.75      , 0.75438596, 0.75      ,\n",
       "       0.75      , 0.75471698, 0.75      , 0.75      , 0.75247525,\n",
       "       0.75070028, 0.75      , 0.73333333, 0.76470588, 0.74285714,\n",
       "       0.75167785, 0.7483871 , 0.75308642, 0.74285714, 0.72727273,\n",
       "       0.75      , 0.75      , 0.74509804, 0.73913043, 0.76923077,\n",
       "       0.75      , 0.75      , 0.75      , 0.75675676, 0.74468085,\n",
       "       0.75      , 0.74193548, 0.74074074, 0.75      , 0.75      ,\n",
       "       0.74698795, 0.75510204, 0.75111111, 0.74418605, 0.75      ,\n",
       "       0.75      , 0.75      , 0.75      , 0.76      , 0.75      ,\n",
       "       0.75      , 0.75609756, 0.76      , 0.74468085, 0.75280899,\n",
       "       0.75      , 0.75862069, 0.74468085, 0.74074074, 0.75555556,\n",
       "       0.75      , 0.75675676, 0.74846626, 0.75      , 0.74666667,\n",
       "       0.76190476, 0.74074074, 0.75      , 0.74358974, 0.74757282,\n",
       "       0.74418605, 0.75      , 0.75      , 0.75280899, 0.74545455,\n",
       "       0.74853801, 0.75      , 0.75555556, 0.75177305, 0.75471698,\n",
       "       0.75      , 0.75138122, 0.74074074, 0.75206612, 0.75      ,\n",
       "       0.75      , 0.74576271, 0.75862069, 0.74814815, 0.76470588,\n",
       "       0.75      , 0.75      , 0.74626866, 0.75      , 0.75229358,\n",
       "       0.75      , 0.74842767, 0.74757282, 0.76190476, 0.75409836,\n",
       "       0.73684211, 0.75862069, 0.75084175, 0.75      , 0.74919614,\n",
       "       0.76190476, 0.72727273, 0.74911661, 0.74829932, 0.75036496,\n",
       "       0.75      , 0.75862069, 0.74647887, 0.7486911 , 0.75      ,\n",
       "       0.75206612, 0.73913043, 0.74683544, 0.74698795, 0.74647887,\n",
       "       0.75102041, 0.74468085, 0.73913043, 0.75      , 0.73913043,\n",
       "       0.75      , 0.75862069, 0.74285714, 0.75609756, 0.76470588,\n",
       "       0.75324675, 0.75510204, 0.75      , 0.74193548, 0.73684211,\n",
       "       0.72727273, 0.74937343, 0.74666667, 0.74418605, 0.75      ,\n",
       "       0.74647887, 0.76190476, 0.75      , 0.75      , 0.74782609,\n",
       "       0.75      , 0.75      , 0.75324675, 0.75159236, 0.73684211,\n",
       "       0.75862069, 0.75238095, 0.7480315 , 0.75167785, 0.76190476,\n",
       "       0.75757576, 0.74193548, 0.74468085, 0.75555556, 0.75438596,\n",
       "       0.75862069, 0.75      , 0.75238095, 0.75362319, 0.74418605,\n",
       "       0.75113122, 0.75308642, 0.73333333, 0.75      , 0.74850299,\n",
       "       0.75092937, 0.75268817, 0.74358974, 0.74626866, 0.73333333,\n",
       "       0.75      , 0.76190476, 0.72727273, 0.75294118, 0.76      ,\n",
       "       0.75      , 0.7515528 , 0.76923077, 0.76190476, 0.73684211,\n",
       "       0.74698795, 0.75      , 0.74766355, 0.75      , 0.75471698,\n",
       "       0.75      , 0.75757576, 0.75      , 0.74285714, 0.75      ,\n",
       "       0.75      , 0.76923077, 0.74285714, 0.74074074, 0.75      ,\n",
       "       0.74626866, 0.75085324, 0.75      , 0.75081967, 0.75757576,\n",
       "       0.75      , 0.75342466, 0.75438596, 0.76470588, 0.73684211,\n",
       "       0.75229358, 0.74698795, 0.75070028, 0.75      , 0.75609756,\n",
       "       0.75757576, 0.76190476, 0.75193798, 0.75229358, 0.73913043,\n",
       "       0.74857143, 0.75675676, 0.75      , 0.75862069, 0.75      ,\n",
       "       0.74285714, 0.75757576, 0.7515528 , 0.75      , 0.75      ,\n",
       "       0.75238095, 0.75      , 0.75384615, 0.75675676, 0.74545455,\n",
       "       0.76190476, 0.75      , 0.73333333, 0.74358974, 0.74074074,\n",
       "       0.75213675, 0.75438596, 0.75100402, 0.75757576, 0.74891775,\n",
       "       0.76      , 0.74468085, 0.74545455, 0.74358974, 0.74842767,\n",
       "       0.74860335, 0.76923077, 0.74895397, 0.75      , 0.75      ,\n",
       "       0.76923077, 0.74666667, 0.75757576, 0.75      , 0.75091575,\n",
       "       0.75      , 0.75      , 0.73913043, 0.75      , 0.76923077,\n",
       "       0.76190476, 0.75      , 0.75862069, 0.74285714, 0.74863388,\n",
       "       0.76      , 0.75      , 0.76190476, 0.75      , 0.76190476,\n",
       "       0.74193548, 0.76      , 0.75135135, 0.75      , 0.75172414,\n",
       "       0.74782609, 0.75      , 0.75      , 0.75      , 0.75471698,\n",
       "       0.75342466, 0.76      , 0.74906367, 0.74074074, 0.74509804,\n",
       "       0.76      , 0.73913043, 0.75268817, 0.75438596, 0.75126904,\n",
       "       0.74193548, 0.74074074, 0.75      , 0.75308642, 0.74193548,\n",
       "       0.75061728, 0.75342466, 0.74666667, 0.73913043, 0.74509804,\n",
       "       0.75119617, 0.75510204, 0.75609756, 0.75115207, 0.73913043,\n",
       "       0.76923077, 0.72727273, 0.76190476, 0.74358974, 0.74647887,\n",
       "       0.74418605, 0.75151515, 0.74766355, 0.74829932, 0.75757576,\n",
       "       0.75      , 0.74736842, 0.75      , 0.74468085, 0.75092937,\n",
       "       0.74782609, 0.74647887, 0.75      , 0.76470588, 0.75280899,\n",
       "       0.76190476, 0.75308642, 0.74626866, 0.75862069, 0.75      ,\n",
       "       0.74903475, 0.75182482, 0.75      , 0.74418605, 0.74509804,\n",
       "       0.75      , 0.74853801, 0.75      , 0.74846626, 0.74789916,\n",
       "       0.74468085, 0.75221239, 0.74576271, 0.75102041, 0.75      ,\n",
       "       0.75138122, 0.75135135, 0.73333333, 0.74814815, 0.75555556,\n",
       "       0.75      , 0.75510204, 0.75      , 0.74468085, 0.75      ,\n",
       "       0.75609756, 0.74829932, 0.75675676, 0.76923077, 0.75      ,\n",
       "       0.75510204, 0.75471698, 0.75      , 0.73913043, 0.76923077,\n",
       "       0.75078864, 0.74285714, 0.74757282, 0.75115207, 0.76923077,\n",
       "       0.74545455, 0.7480315 , 0.75675676, 0.75609756, 0.75      ,\n",
       "       0.75      , 0.75      , 0.75      , 0.75510204, 0.74603175,\n",
       "       0.75409836, 0.75103734, 0.75      , 0.74712644, 0.74358974,\n",
       "       0.74647887, 0.75      , 0.75      , 0.75510204, 0.74766355,\n",
       "       0.72727273, 0.74683544, 0.75      ])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user percentage of training examples \n",
    "Ztr_np_rated/Zrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25      , 0.25806452, 0.25925926, 0.25      , 0.25142857,\n",
       "       0.25118483, 0.25062035, 0.25423729, 0.27272727, 0.25      ,\n",
       "       0.24861878, 0.25490196, 0.25      , 0.24489796, 0.25      ,\n",
       "       0.25      , 0.25      , 0.24909747, 0.25      , 0.25      ,\n",
       "       0.25139665, 0.25      , 0.25165563, 0.25      , 0.25641026,\n",
       "       0.25233645, 0.24      , 0.25316456, 0.23529412, 0.25581395,\n",
       "       0.25      , 0.24390244, 0.25      , 0.25      , 0.24      ,\n",
       "       0.25      , 0.24561404, 0.24793388, 0.27272727, 0.25714286,\n",
       "       0.25      , 0.25136612, 0.24886878, 0.25165563, 0.25      ,\n",
       "       0.25925926, 0.24      , 0.24242424, 0.25116279, 0.25      ,\n",
       "       0.26086957, 0.25      , 0.25      , 0.24615385, 0.23809524,\n",
       "       0.2513369 , 0.24528302, 0.24675325, 0.2513089 , 0.25      ,\n",
       "       0.23809524, 0.25      , 0.24731183, 0.25      , 0.25      ,\n",
       "       0.26315789, 0.26666667, 0.23529412, 0.24615385, 0.2519084 ,\n",
       "       0.26315789, 0.24817518, 0.24242424, 0.25641026, 0.25316456,\n",
       "       0.24390244, 0.25      , 0.23809524, 0.25454545, 0.24137931,\n",
       "       0.24137931, 0.25      , 0.2516129 , 0.25      , 0.25      ,\n",
       "       0.26086957, 0.25118483, 0.23809524, 0.25      , 0.25      ,\n",
       "       0.24489796, 0.25      , 0.25      , 0.25      , 0.25179856,\n",
       "       0.25      , 0.25396825, 0.25925926, 0.25      , 0.25423729,\n",
       "       0.25373134, 0.25      , 0.24137931, 0.25225225, 0.26086957,\n",
       "       0.25      , 0.27272727, 0.24242424, 0.24786325, 0.2481203 ,\n",
       "       0.25      , 0.26086957, 0.25490196, 0.25      , 0.25      ,\n",
       "       0.25174825, 0.25581395, 0.25352113, 0.24861878, 0.23076923,\n",
       "       0.24324324, 0.24590164, 0.25925926, 0.25      , 0.25274725,\n",
       "       0.24444444, 0.26086957, 0.25      , 0.26666667, 0.24929178,\n",
       "       0.26666667, 0.27272727, 0.23076923, 0.24      , 0.25454545,\n",
       "       0.25714286, 0.25531915, 0.25490196, 0.25      , 0.23809524,\n",
       "       0.25233645, 0.24242424, 0.25      , 0.25242718, 0.25      ,\n",
       "       0.24137931, 0.25      , 0.24615385, 0.25      , 0.25      ,\n",
       "       0.25081433, 0.24528302, 0.26086957, 0.25490196, 0.27272727,\n",
       "       0.24324324, 0.25490196, 0.24855491, 0.25233645, 0.25      ,\n",
       "       0.24137931, 0.23809524, 0.26086957, 0.25396825, 0.26666667,\n",
       "       0.25      , 0.24637681, 0.24637681, 0.24324324, 0.27272727,\n",
       "       0.25      , 0.25925926, 0.25581395, 0.24858757, 0.26315789,\n",
       "       0.25396825, 0.25217391, 0.24908425, 0.23809524, 0.25396825,\n",
       "       0.25057471, 0.25      , 0.24528302, 0.25099602, 0.25      ,\n",
       "       0.25      , 0.25      , 0.25      , 0.2513369 , 0.25423729,\n",
       "       0.25925926, 0.25714286, 0.24793388, 0.24918033, 0.25      ,\n",
       "       0.25641026, 0.25423729, 0.24861878, 0.25      , 0.25      ,\n",
       "       0.24870466, 0.25      , 0.25581395, 0.23809524, 0.27272727,\n",
       "       0.25      , 0.25217391, 0.24242424, 0.24242424, 0.25      ,\n",
       "       0.24324324, 0.24      , 0.25396825, 0.25      , 0.24731183,\n",
       "       0.2519084 , 0.25      , 0.24528302, 0.25      , 0.27272727,\n",
       "       0.24657534, 0.25064599, 0.24761905, 0.24822695, 0.25925926,\n",
       "       0.24      , 0.24137931, 0.23809524, 0.26666667, 0.2481203 ,\n",
       "       0.23809524, 0.24731183, 0.25454545, 0.25      , 0.25531915,\n",
       "       0.25      , 0.25      , 0.24137931, 0.25157233, 0.25      ,\n",
       "       0.26086957, 0.25      , 0.24691358, 0.25210084, 0.27272727,\n",
       "       0.25128205, 0.23076923, 0.25      , 0.2484472 , 0.24590164,\n",
       "       0.24675325, 0.23809524, 0.24742268, 0.25157233, 0.25301205,\n",
       "       0.25120773, 0.24561404, 0.26086957, 0.26086957, 0.25      ,\n",
       "       0.25925926, 0.25      , 0.25203252, 0.25      , 0.26086957,\n",
       "       0.26086957, 0.24864865, 0.25      , 0.25077399, 0.24637681,\n",
       "       0.25179856, 0.25490196, 0.27272727, 0.25352113, 0.25263158,\n",
       "       0.25096525, 0.25925926, 0.26086957, 0.24884793, 0.24806202,\n",
       "       0.23076923, 0.27272727, 0.24528302, 0.25531915, 0.25      ,\n",
       "       0.25      , 0.25806452, 0.25333333, 0.25925926, 0.25333333,\n",
       "       0.25      , 0.25      , 0.25      , 0.25333333, 0.25      ,\n",
       "       0.25170068, 0.25      , 0.2519685 , 0.25      , 0.25      ,\n",
       "       0.25090909, 0.23809524, 0.25      , 0.23076923, 0.25225225,\n",
       "       0.25      , 0.25      , 0.24937028, 0.25      , 0.23809524,\n",
       "       0.25170068, 0.25112108, 0.2519084 , 0.24897959, 0.25287356,\n",
       "       0.25333333, 0.27272727, 0.25287356, 0.26086957, 0.24675325,\n",
       "       0.248     , 0.25490196, 0.24719101, 0.24242424, 0.25352113,\n",
       "       0.2513369 , 0.25      , 0.25088339, 0.24615385, 0.25170068,\n",
       "       0.25714286, 0.25136612, 0.23076923, 0.24924925, 0.27272727,\n",
       "       0.24615385, 0.23529412, 0.25333333, 0.2519685 , 0.25      ,\n",
       "       0.23809524, 0.24875622, 0.24894515, 0.25263158, 0.25      ,\n",
       "       0.24870466, 0.25125628, 0.24137931, 0.24390244, 0.24      ,\n",
       "       0.25      , 0.23809524, 0.24      , 0.24892704, 0.23076923,\n",
       "       0.25      , 0.25      , 0.25581395, 0.25925926, 0.25490196,\n",
       "       0.24793388, 0.24      , 0.25080386, 0.25      , 0.24137931,\n",
       "       0.24242424, 0.24137931, 0.24444444, 0.27272727, 0.25333333,\n",
       "       0.25490196, 0.24242424, 0.24892704, 0.24817518, 0.25      ,\n",
       "       0.26666667, 0.24242424, 0.25066667, 0.25      , 0.24691358,\n",
       "       0.2519685 , 0.24528302, 0.25352113, 0.27272727, 0.24911032,\n",
       "       0.26086957, 0.25      , 0.25      , 0.25092251, 0.25806452,\n",
       "       0.24793388, 0.25225225, 0.25      , 0.24832215, 0.24561404,\n",
       "       0.25925926, 0.25490196, 0.25      , 0.2507837 , 0.27272727,\n",
       "       0.24836601, 0.25      , 0.24      , 0.25      , 0.24966079,\n",
       "       0.25146199, 0.24778761, 0.25925926, 0.25123153, 0.25      ,\n",
       "       0.24137931, 0.25490196, 0.24      , 0.24      , 0.25      ,\n",
       "       0.2494929 , 0.24931507, 0.25      , 0.25      , 0.25      ,\n",
       "       0.25806452, 0.24742268, 0.25      , 0.25      , 0.25      ,\n",
       "       0.24752475, 0.25806452, 0.25454545, 0.25120773, 0.24615385,\n",
       "       0.23809524, 0.25806452, 0.24390244, 0.25      , 0.25065963,\n",
       "       0.24827586, 0.25095057, 0.24242424, 0.25806452, 0.25490196,\n",
       "       0.25      , 0.25174825, 0.25      , 0.25      , 0.25185185,\n",
       "       0.25      , 0.25179856, 0.26315789, 0.25333333, 0.25      ,\n",
       "       0.24489796, 0.25242718, 0.25      , 0.25      , 0.24867725,\n",
       "       0.24884793, 0.24909747, 0.25136612, 0.25423729, 0.25      ,\n",
       "       0.26086957, 0.24242424, 0.2481203 , 0.24528302, 0.25      ,\n",
       "       0.24752475, 0.25      , 0.25174825, 0.25581395, 0.24561404,\n",
       "       0.25806452, 0.25095057, 0.25714286, 0.25076453, 0.25      ,\n",
       "       0.25301205, 0.25714286, 0.24778761, 0.24752475, 0.25      ,\n",
       "       0.25      , 0.23076923, 0.25423729, 0.25179856, 0.23076923,\n",
       "       0.24867725, 0.25108225, 0.24675325, 0.24770642, 0.24561404,\n",
       "       0.24242424, 0.25454545, 0.25185185, 0.25531915, 0.24882629,\n",
       "       0.24806202, 0.25089606, 0.24832215, 0.25490196, 0.24888889,\n",
       "       0.24657534, 0.24324324, 0.25      , 0.25099602, 0.25      ,\n",
       "       0.24793388, 0.24137931, 0.25287356, 0.24242424, 0.26666667,\n",
       "       0.25      , 0.23809524, 0.27272727, 0.24742268, 0.25      ,\n",
       "       0.23809524, 0.24324324, 0.24657534, 0.24489796, 0.26086957,\n",
       "       0.25333333, 0.26666667, 0.25      , 0.24836601, 0.25925926,\n",
       "       0.25      , 0.24817518, 0.24528302, 0.25581395, 0.24444444,\n",
       "       0.26666667, 0.24817518, 0.25      , 0.25      , 0.24770642,\n",
       "       0.25153374, 0.24897959, 0.24691358, 0.25      , 0.25396825,\n",
       "       0.2481203 , 0.25185185, 0.24873096, 0.25806452, 0.24691358,\n",
       "       0.25423729, 0.26086957, 0.2516129 , 0.24      , 0.25      ,\n",
       "       0.25149701, 0.25      , 0.25      , 0.24561404, 0.25      ,\n",
       "       0.25      , 0.24528302, 0.25      , 0.25      , 0.24752475,\n",
       "       0.24929972, 0.25      , 0.26666667, 0.23529412, 0.25714286,\n",
       "       0.24832215, 0.2516129 , 0.24691358, 0.25714286, 0.27272727,\n",
       "       0.25      , 0.25      , 0.25490196, 0.26086957, 0.23076923,\n",
       "       0.25      , 0.25      , 0.25      , 0.24324324, 0.25531915,\n",
       "       0.25      , 0.25806452, 0.25925926, 0.25      , 0.25      ,\n",
       "       0.25301205, 0.24489796, 0.24888889, 0.25581395, 0.25      ,\n",
       "       0.25      , 0.25      , 0.25      , 0.24      , 0.25      ,\n",
       "       0.25      , 0.24390244, 0.24      , 0.25531915, 0.24719101,\n",
       "       0.25      , 0.24137931, 0.25531915, 0.25925926, 0.24444444,\n",
       "       0.25      , 0.24324324, 0.25153374, 0.25      , 0.25333333,\n",
       "       0.23809524, 0.25925926, 0.25      , 0.25641026, 0.25242718,\n",
       "       0.25581395, 0.25      , 0.25      , 0.24719101, 0.25454545,\n",
       "       0.25146199, 0.25      , 0.24444444, 0.24822695, 0.24528302,\n",
       "       0.25      , 0.24861878, 0.25925926, 0.24793388, 0.25      ,\n",
       "       0.25      , 0.25423729, 0.24137931, 0.25185185, 0.23529412,\n",
       "       0.25      , 0.25      , 0.25373134, 0.25      , 0.24770642,\n",
       "       0.25      , 0.25157233, 0.25242718, 0.23809524, 0.24590164,\n",
       "       0.26315789, 0.24137931, 0.24915825, 0.25      , 0.25080386,\n",
       "       0.23809524, 0.27272727, 0.25088339, 0.25170068, 0.24963504,\n",
       "       0.25      , 0.24137931, 0.25352113, 0.2513089 , 0.25      ,\n",
       "       0.24793388, 0.26086957, 0.25316456, 0.25301205, 0.25352113,\n",
       "       0.24897959, 0.25531915, 0.26086957, 0.25      , 0.26086957,\n",
       "       0.25      , 0.24137931, 0.25714286, 0.24390244, 0.23529412,\n",
       "       0.24675325, 0.24489796, 0.25      , 0.25806452, 0.26315789,\n",
       "       0.27272727, 0.25062657, 0.25333333, 0.25581395, 0.25      ,\n",
       "       0.25352113, 0.23809524, 0.25      , 0.25      , 0.25217391,\n",
       "       0.25      , 0.25      , 0.24675325, 0.24840764, 0.26315789,\n",
       "       0.24137931, 0.24761905, 0.2519685 , 0.24832215, 0.23809524,\n",
       "       0.24242424, 0.25806452, 0.25531915, 0.24444444, 0.24561404,\n",
       "       0.24137931, 0.25      , 0.24761905, 0.24637681, 0.25581395,\n",
       "       0.24886878, 0.24691358, 0.26666667, 0.25      , 0.25149701,\n",
       "       0.24907063, 0.24731183, 0.25641026, 0.25373134, 0.26666667,\n",
       "       0.25      , 0.23809524, 0.27272727, 0.24705882, 0.24      ,\n",
       "       0.25      , 0.2484472 , 0.23076923, 0.23809524, 0.26315789,\n",
       "       0.25301205, 0.25      , 0.25233645, 0.25      , 0.24528302,\n",
       "       0.25      , 0.24242424, 0.25      , 0.25714286, 0.25      ,\n",
       "       0.25      , 0.23076923, 0.25714286, 0.25925926, 0.25      ,\n",
       "       0.25373134, 0.24914676, 0.25      , 0.24918033, 0.24242424,\n",
       "       0.25      , 0.24657534, 0.24561404, 0.23529412, 0.26315789,\n",
       "       0.24770642, 0.25301205, 0.24929972, 0.25      , 0.24390244,\n",
       "       0.24242424, 0.23809524, 0.24806202, 0.24770642, 0.26086957,\n",
       "       0.25142857, 0.24324324, 0.25      , 0.24137931, 0.25      ,\n",
       "       0.25714286, 0.24242424, 0.2484472 , 0.25      , 0.25      ,\n",
       "       0.24761905, 0.25      , 0.24615385, 0.24324324, 0.25454545,\n",
       "       0.23809524, 0.25      , 0.26666667, 0.25641026, 0.25925926,\n",
       "       0.24786325, 0.24561404, 0.24899598, 0.24242424, 0.25108225,\n",
       "       0.24      , 0.25531915, 0.25454545, 0.25641026, 0.25157233,\n",
       "       0.25139665, 0.23076923, 0.25104603, 0.25      , 0.25      ,\n",
       "       0.23076923, 0.25333333, 0.24242424, 0.25      , 0.24908425,\n",
       "       0.25      , 0.25      , 0.26086957, 0.25      , 0.23076923,\n",
       "       0.23809524, 0.25      , 0.24137931, 0.25714286, 0.25136612,\n",
       "       0.24      , 0.25      , 0.23809524, 0.25      , 0.23809524,\n",
       "       0.25806452, 0.24      , 0.24864865, 0.25      , 0.24827586,\n",
       "       0.25217391, 0.25      , 0.25      , 0.25      , 0.24528302,\n",
       "       0.24657534, 0.24      , 0.25093633, 0.25925926, 0.25490196,\n",
       "       0.24      , 0.26086957, 0.24731183, 0.24561404, 0.24873096,\n",
       "       0.25806452, 0.25925926, 0.25      , 0.24691358, 0.25806452,\n",
       "       0.24938272, 0.24657534, 0.25333333, 0.26086957, 0.25490196,\n",
       "       0.24880383, 0.24489796, 0.24390244, 0.24884793, 0.26086957,\n",
       "       0.23076923, 0.27272727, 0.23809524, 0.25641026, 0.25352113,\n",
       "       0.25581395, 0.24848485, 0.25233645, 0.25170068, 0.24242424,\n",
       "       0.25      , 0.25263158, 0.25      , 0.25531915, 0.24907063,\n",
       "       0.25217391, 0.25352113, 0.25      , 0.23529412, 0.24719101,\n",
       "       0.23809524, 0.24691358, 0.25373134, 0.24137931, 0.25      ,\n",
       "       0.25096525, 0.24817518, 0.25      , 0.25581395, 0.25490196,\n",
       "       0.25      , 0.25146199, 0.25      , 0.25153374, 0.25210084,\n",
       "       0.25531915, 0.24778761, 0.25423729, 0.24897959, 0.25      ,\n",
       "       0.24861878, 0.24864865, 0.26666667, 0.25185185, 0.24444444,\n",
       "       0.25      , 0.24489796, 0.25      , 0.25531915, 0.25      ,\n",
       "       0.24390244, 0.25170068, 0.24324324, 0.23076923, 0.25      ,\n",
       "       0.24489796, 0.24528302, 0.25      , 0.26086957, 0.23076923,\n",
       "       0.24921136, 0.25714286, 0.25242718, 0.24884793, 0.23076923,\n",
       "       0.25454545, 0.2519685 , 0.24324324, 0.24390244, 0.25      ,\n",
       "       0.25      , 0.25      , 0.25      , 0.24489796, 0.25396825,\n",
       "       0.24590164, 0.24896266, 0.25      , 0.25287356, 0.25641026,\n",
       "       0.25352113, 0.25      , 0.25      , 0.24489796, 0.25233645,\n",
       "       0.27272727, 0.25316456, 0.25      ])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user percentage of test examples \n",
    "Ztst_np_rated/Zrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7020148462354189"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Ztst_np_rated >=10).sum()/Nusers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average number of per user rated elements 26.51961823966066\n",
      "standard deviation 25.21894344003685\n"
     ]
    }
   ],
   "source": [
    "print('average number of per user rated elements', np.mean(Ztst_np_rated) )\n",
    "print('standard deviation', np.std(Ztst_np_rated) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
