{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Normalization test of split and metrics functions \n",
    "\n",
    "In this notebook we check the consistency of split and metrics function. We first check this using an artificial dataset and then using the movielens 100k and 1m data used in the recommender tests.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.6 |Anaconda custom (64-bit)| (default, Jun 28 2018, 11:07:29) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "Pandas version: 0.23.4\n"
     ]
    }
   ],
   "source": [
    "# set the environment path to find Recommenders\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import itertools\n",
    "import time \n",
    "\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_random_split, python_stratified_split\n",
    "from reco_utils.dataset.numpy_splitters import numpy_stratified_split\n",
    "from reco_utils.dataset.sparse import AffinityMatrix\n",
    "\n",
    "from reco_utils.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "## 1 Artificial dataset \n",
    "\n",
    "For debugging purpose it is useful to generate random sparse matrices. The function `affinity_matrix()` generates a  random rating matrix with a specified degree of sparsness. Realistic user/affinity matrices show a high degree of sparsness;  for example, the sparsness of the movielens dataset is $\\ge 90$%, depending on the particular chosen data size, e.g. movielens 100k $\\simeq 93$%, movielens 1m $\\simeq 95$% etc... Once the sparsness is fixed, the remaining ratings are sampled with equal probabilities. In a realistic datset, rating probabilities are not uniform.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinity_matrix(users, items, ratings, spars):\n",
    "\n",
    "    '''\n",
    "    Generate a random user/item affinity matrix. By increasing the likehood of 0 elements we simulate \n",
    "    a typical recommeding situation where the input matrix is highly sparse. \n",
    "    \n",
    "    Args: \n",
    "        users (int): number of users (rows).\n",
    "        items (int): number of items (columns).\n",
    "        ratings (int): rating scale, e.g. 5 meaning rates are from 1 to 5.\n",
    "        spars: probablity of obtaining zero. This roughly correponds to the sparsness. \n",
    "               of the generated matrix. If spars = 0 then the affinity matrix is dense. \n",
    "    \n",
    "    Returns: \n",
    "        X (np array, int): sparse user/affinity matrix \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    np.random.seed(123)\n",
    "\n",
    "    s= [(1-spars)/5]*5 #uniform probability for the 5 ratings\n",
    "    s.append(spars) \n",
    "    P= s[::-1] \n",
    "    \n",
    "    # generates the user/item affinity matrix. Ratings are from 1 to 5, with 0s denoting unrated items\n",
    "    X= np.random.choice(ratings+1, (users,items), p = P)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [2, 0, 2, ..., 0, 3, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate the random sparse matrix. In this example we choose a ~80% sparsness and the matrix dimension are chosen \n",
    "#with the same ratio of item/user ~ 1.78 of the movielens 100k dataset  \n",
    "X = affinity_matrix(users=30,items=53, ratings= 5, spars= 0.8)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.37106918238995"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the sparsness of the dataset#\n",
    "\n",
    "zero = (X == 0).sum()  # number of unrated items\n",
    "total = X.shape[0] * X.shape[1]  # number of elements in the matrix\n",
    "sparsness = zero / total * 100  # Percentage of zeros in the matrix\n",
    "\n",
    "sparsness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  6, 13,  9, 12, 12, 11, 11, 11, 14, 10,  9, 15, 11, 15, 11,  9,\n",
       "        9,  3,  9,  8, 13, 12, 11, 13, 16, 19, 10, 12,  7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of ratings per user\n",
    "rated = np.sum(X != 0, axis=1)\n",
    "rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total number of rated items \n",
    "total_rated = rated.sum()\n",
    "total_rated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to simulate the recommendation task, we split this dataset into train and test set and use the latter to evaluate precision@k. Below, we compare two different split strategies, the first is the **global** split of `python_random_split`and the second is the **local** split `of numpy_stratified_split`. In order to apply the former splitter we first need to map X to a dataframe representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_to_df(X):\n",
    "\n",
    "        \"\"\"\n",
    "        Map the user/affinity matrix to a pd dataframe\n",
    "\n",
    "        \"\"\"\n",
    "        m, n = X.shape #obtain the matrix dimensions: m = #users, n=#items \n",
    "\n",
    "        userids = []\n",
    "\n",
    "        for i in range(1, m+1):\n",
    "            userids.extend([i]*n)\n",
    "\n",
    "\n",
    "        itemids = [i for i in range(1, n+1)]*m\n",
    "        ratings = np.reshape(X, -1)\n",
    "\n",
    "        #create dataframe\n",
    "        results = pd.DataFrame.from_dict(\n",
    "                        {\n",
    "                            'user': userids,\n",
    "                            'item': itemids,\n",
    "                            'rating': ratings,\n",
    "                         }\n",
    "                    )\n",
    "\n",
    "        #here we eliminate the missing ratings to obtain a standard form of the df as that of real dataframe.\n",
    "        results = results[results.rating !=0]\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user  item  rating\n",
       "6      1     7       5\n",
       "21     1    22       2\n",
       "37     1    38       3\n",
       "38     1    39       4\n",
       "44     1    45       2\n",
       "47     1    48       5\n",
       "51     1    52       1\n",
       "58     2     6       2\n",
       "64     2    12       2\n",
       "71     2    19       3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a pandas df \n",
    "X_df = sparse_to_df(X)\n",
    "X_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Splitting \n",
    "\n",
    "Splitting data in an unsupervised setting generally works differently than in the supervised one. \n",
    "\n",
    "Let us first consider a typical supervised learning problem, for example a binary classification problem. We are given a matrix $X^{\\mu}_i$, where $\\mu \\in [1, m]$ is the example index and $i \\in [1,n]$ is the feature index. We are also given a ground truth vector $y^{\\mu}$. The matrix $\\hat{X}$ is generally dense and we want to cut a certain percentage `t` of examples for the training set and `(1-t)` for the test set. In this case $Xtr^{\\mu}_i$ contains the **same** number of features (columns) but different examples (rows) and we split $y^{\\mu}$ accordingly. \n",
    "\n",
    "In the unspervised case, no ground truth vector is provided. In the recommendation case, the user/item affinity matrix contains the ratings as training examples; the only way to verify if the recommendation is correct is to cut part of the ratings for the test set: the ratings are in this case the examples. For the same user we can then verify if the prediction is correct or not by comparing to the test set. Due to the unequal number of ratings per user, we need to make sure that each user contributes the same number of train/test examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Python Random splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data using the random split \n",
    "Xtr_random, Xtst_random = python_random_split(X_df, ratio = 0.75, seed= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>26</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user  item  rating\n",
       "85       2    33       2\n",
       "763     15    22       5\n",
       "286      6    22       5\n",
       "1139    22    27       2\n",
       "1362    26    38       4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtst_random.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global % of rated items in the train set 75.0\n",
      "global % of rated items in the test set 25.0\n"
     ]
    }
   ],
   "source": [
    "print( 'global % of rated items in the train set', (len(Xtr_random.rating)/total_rated)*100 )\n",
    "print( 'global % of rated items in the test set', (len(Xtst_random.rating)/total_rated)*100 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check now the per-user percentage of train/tes set example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user\n",
       "1     1.524390\n",
       "2     1.219512\n",
       "3     3.048780\n",
       "4     1.219512\n",
       "5     2.743902\n",
       "6     2.134146\n",
       "7     3.353659\n",
       "8     2.134146\n",
       "9     2.743902\n",
       "10    3.048780\n",
       "11    2.743902\n",
       "12    2.743902\n",
       "13    3.963415\n",
       "14    2.134146\n",
       "15    3.963415\n",
       "16    2.134146\n",
       "17    1.829268\n",
       "18    2.134146\n",
       "20    1.829268\n",
       "21    2.134146\n",
       "22    3.353659\n",
       "23    2.134146\n",
       "24    2.743902\n",
       "25    3.353659\n",
       "26    3.963415\n",
       "27    4.573171\n",
       "28    2.439024\n",
       "29    1.829268\n",
       "30    1.829268\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user % of training example \n",
    "(Xtr_random.groupby(by= 'user').rating.count()/total_rated)*100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above splitter often introduces missing users. Above, user 19 is missing for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user\n",
       "1     0.609756\n",
       "2     0.609756\n",
       "3     0.914634\n",
       "4     1.524390\n",
       "5     0.914634\n",
       "6     1.524390\n",
       "8     1.219512\n",
       "9     0.609756\n",
       "10    1.219512\n",
       "11    0.304878\n",
       "13    0.609756\n",
       "14    1.219512\n",
       "15    0.609756\n",
       "16    1.219512\n",
       "17    0.914634\n",
       "18    0.609756\n",
       "19    0.914634\n",
       "20    0.914634\n",
       "21    0.304878\n",
       "22    0.609756\n",
       "23    1.524390\n",
       "24    0.609756\n",
       "25    0.609756\n",
       "26    0.914634\n",
       "27    1.219512\n",
       "28    0.609756\n",
       "29    1.829268\n",
       "30    0.304878\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user % of test example \n",
    "(Xtst_random.groupby(by= 'user').rating.count()/total_rated)*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6209876543209876"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean ratio of train/test and standard deviation \n",
    "np.mean(Xtr_random.groupby(by= 'user').rating.count()/(Xtst_random.groupby(by= 'user').rating.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.089984900572549"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#std of train/test and standard deviation \n",
    "np.std(Xtr_random.groupby(by= 'user').rating.count()/(Xtst_random.groupby(by= 'user').rating.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the fluctuations around the mean ratio of train/test examples is too large. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Python Stratified splitter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data using the random split \n",
    "Xtr_strat, Xtst_strat = python_stratified_split(X_df, ratio = 0.75, seed= 123, col_user ='user', col_item= 'item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user  item  rating\n",
       "47      1    48       5\n",
       "51      1    52       1\n",
       "71      2    19       3\n",
       "91      2    39       5\n",
       "125     3    20       5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtst_strat.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global % of rated items in the train set 74.6951219512195\n",
      "global % of rated items in the test set 25.304878048780488\n"
     ]
    }
   ],
   "source": [
    "print( 'global % of rated items in the train set', (len(Xtr_strat.rating)/total_rated)*100 )\n",
    "print( 'global % of rated items in the test set', (len(Xtst_strat.rating)/total_rated)*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user\n",
       "1     1.524390\n",
       "2     1.219512\n",
       "3     3.048780\n",
       "4     2.134146\n",
       "5     2.743902\n",
       "6     2.743902\n",
       "7     2.439024\n",
       "8     2.439024\n",
       "9     2.439024\n",
       "10    3.048780\n",
       "11    2.439024\n",
       "12    2.134146\n",
       "13    3.353659\n",
       "14    2.439024\n",
       "15    3.353659\n",
       "16    2.439024\n",
       "17    2.134146\n",
       "18    2.134146\n",
       "19    0.609756\n",
       "20    2.134146\n",
       "21    1.829268\n",
       "22    3.048780\n",
       "23    2.743902\n",
       "24    2.439024\n",
       "25    3.048780\n",
       "26    3.658537\n",
       "27    4.268293\n",
       "28    2.439024\n",
       "29    2.743902\n",
       "30    1.524390\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user % of training example \n",
    "(Xtr_strat.groupby(by= 'user').rating.count()/total_rated)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the sum of the above percentages is 74.74% as it should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user\n",
       "1     0.609756\n",
       "2     0.609756\n",
       "3     0.914634\n",
       "4     0.609756\n",
       "5     0.914634\n",
       "6     0.914634\n",
       "7     0.914634\n",
       "8     0.914634\n",
       "9     0.914634\n",
       "10    1.219512\n",
       "11    0.609756\n",
       "12    0.609756\n",
       "13    1.219512\n",
       "14    0.914634\n",
       "15    1.219512\n",
       "16    0.914634\n",
       "17    0.609756\n",
       "18    0.609756\n",
       "19    0.304878\n",
       "20    0.609756\n",
       "21    0.609756\n",
       "22    0.914634\n",
       "23    0.914634\n",
       "24    0.914634\n",
       "25    0.914634\n",
       "26    1.219512\n",
       "27    1.524390\n",
       "28    0.609756\n",
       "29    0.914634\n",
       "30    0.609756\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user % of test example \n",
    "(Xtst_strat.groupby(by= 'user').rating.count()/total_rated)*100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the number of users is the same in both train and test. We can check again the mean train/test set ratio and its std. We find that in this case the fluctuations are much smaller than in the random splitter, meaning a more balanced per user example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9766666666666666"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(Xtr_strat.groupby(by= 'user').rating.count()/(Xtst_strat.groupby(by= 'user').rating.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48814842915745305"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(Xtr_strat.groupby(by= 'user').rating.count()/(Xtst_strat.groupby(by= 'user').rating.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case fluctuations (error bars) have a reasonable size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Numpy stratified split \n",
    "\n",
    "In this case the data are split by keeping a per-user, constant percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_np, Xtst_np = numpy_stratified_split(X, ratio = 0.75, seed= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of rated elements in the train/test set \n",
    "Xtr_rated = np.sum(Xtr_np != 0, axis=1)  # number of rated items in the train set\n",
    "Xtst_rated = np.sum(Xtst_np != 0, axis=1)  # number of rated items in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global % of rated items in the train set 74.6951219512195\n",
      "global % of rated items in the test set 25.304878048780488\n"
     ]
    }
   ],
   "source": [
    "print( 'global % of rated items in the train set', (Xtr_rated.sum() / total_rated)*100 )\n",
    "print( 'global % of rated items in the test set', (Xtst_rated.sum() / total_rated)*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71428571, 0.66666667, 0.76923077, 0.77777778, 0.75      ,\n",
       "       0.75      , 0.72727273, 0.72727273, 0.72727273, 0.71428571,\n",
       "       0.8       , 0.77777778, 0.73333333, 0.72727273, 0.73333333,\n",
       "       0.72727273, 0.77777778, 0.77777778, 0.66666667, 0.77777778,\n",
       "       0.75      , 0.76923077, 0.75      , 0.72727273, 0.76923077,\n",
       "       0.75      , 0.73684211, 0.8       , 0.75      , 0.71428571])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user percentage of training examples \n",
    "Xtr_rated/rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28571429, 0.33333333, 0.23076923, 0.22222222, 0.25      ,\n",
       "       0.25      , 0.27272727, 0.27272727, 0.27272727, 0.28571429,\n",
       "       0.2       , 0.22222222, 0.26666667, 0.27272727, 0.26666667,\n",
       "       0.27272727, 0.22222222, 0.22222222, 0.33333333, 0.22222222,\n",
       "       0.25      , 0.23076923, 0.25      , 0.27272727, 0.23076923,\n",
       "       0.25      , 0.26315789, 0.2       , 0.25      , 0.28571429])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user percentage of test examples \n",
    "Xtst_rated/rated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also in this case the per user, training percentage are not exactly 75% but much closer to it than the previous case. The reason for these fluctuations is due to rounding errors and in principle and can be improven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.976666666666666"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(Xtr_rated/Xtst_rated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.488148429157453"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(Xtr_rated/Xtst_rated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the apparent difference, both the python and stratified splitters produce the same results. The main difference in the scalability, as we show below on the movilens datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Evaluation \n",
    "\n",
    "We now consider the evaluation metrics and their normalization. As an example, we consider precision@k and rmse. As a first step, we are interested in determining the maximum achievable precision for precision@k; conventionally, this is set to one to denote a perfect score, in agreement with the normalization of the corresponding distribution. The definition is\n",
    "\n",
    "$$ p_k = \\frac{1}{m} \\sum_{\\mu=1}^m \\frac{1}{k} \\sum_{i =1}^{min(k, |D_i|)} I(X_p = X_{tst})^{\\mu}_i$$,\n",
    "\n",
    "where $I()$ is known as an indicator \"function\", even thought mathematically is a distribution. An example of this class of distributions is the Dirac delta function $\\delta(X_p - X_{tst})$. The above definition has the (known) problem of not being normalized to 1 if the number of test set elements is less than k, as it can be seen explictly from the above equation. Below we show tha precision@k is often $< 1&  when working with sparse matrices.   \n",
    "\n",
    "We define a maximum achievable precision@k function in order to find out the reference scale when evaluating models. The `max_precision_at_k()` function evaluates the absolute scale in a simple and fast way by directly employing the definition of precision@k. Below we test this function with the result coming from a direct application of `precision_at_k()` and show that it is the same. Then we will use `max_precision_at_k()` for the rest of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_precision_at_k(a,k):\n",
    "    \n",
    "    pk = np.mean(a/k)\n",
    "    \n",
    "    return pk    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Numpy stratified splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return the top_k elements \n",
    "\n",
    "top_k = 5\n",
    "\n",
    "def return_top_k(X_pred, k):\n",
    "\n",
    "    top_items = np.argpartition(-X_pred , range(k), axis=1)[:, :k]  # get the top k items\n",
    "        \n",
    "    score_c = X_pred.copy()  # get a copy of the score matrix\n",
    "    score_c[np.arange(score_c.shape[0])[:, None], top_items] = 0  # set to zero the top_k elements\n",
    "\n",
    "    top_scores = X_pred - score_c  # set to zeros all elements other then the top_k\n",
    "    \n",
    "    return top_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top k matrix using the numpy_splitter result\n",
    "top_np = return_top_k(Xtst_np, top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_precision at k=5, 0.5533333333333333\n"
     ]
    }
   ],
   "source": [
    "#evaluate the maximum achievable prediction using the `max_precision_at_k()` function \n",
    "num_pred_np = np.sum(top_np !=0, axis=1)\n",
    "print('max_precision at k=5,', max_precision_at_k(num_pred_np, top_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we repeat the same calculation using the `precision_at_k()` function. In order to do that, we first need to convert the numpy prediction and test matrices to a pandas df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user  item  rating\n",
       "21      1    22       2\n",
       "38      1    39       4\n",
       "58      2     6       2\n",
       "85      2    33       2\n",
       "120     3    15       3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the prediction matrix to a pandas dataframe \n",
    "pred_np = sparse_to_df(top_np)\n",
    "pred_np.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user  item  rating\n",
       "21      1    22       2\n",
       "38      1    39       4\n",
       "58      2     6       2\n",
       "85      2    33       2\n",
       "120     3    15       3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_np = sparse_to_df(Xtst_np)\n",
    "test_np.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5533333333333333"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_precision = precision_at_k(test_np, pred_np, col_user=\"user\", col_item=\"item\", \n",
    "                               col_rating=\"rating\", col_prediction=\"rating\", \n",
    "                               relevancy_method=\"top_k\", k= top_k)\n",
    "eval_precision "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the same result obtained using `max_precision_at_k()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Python random splitter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `max_k()` function returns a dataframe in wich the number of rated items per user is $\\le k$. This function is used to generate the maximum prediction dataset with k elements; basically, this is a restriction of the original test set to max k items per user.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_k(X,k, group):\n",
    "\n",
    "    counts = np.asarray(X.groupby(by= group).rating.count())\n",
    "    idx = np.where(counts > k)\n",
    "    counts[idx] = k\n",
    "\n",
    "    return counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp_random = max_k(Xtst_random, k=5, group= 'user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5785714285714285"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_precision_at_k(Xp_random,k=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the test set obtained from the random splitter one can achieve a maximum precision of $\\sim 0.58$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Python stratified splitter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python stratified splitter gives the same result of the numpy one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp_strat= max_k(Xtst_strat, k=5, group = 'user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5533333333333333"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_precision_at_k(Xp_strat, k=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the `python random splitter` is the one giving an higher maximum performance. However, this is not the case for the movielens dataset studied below. The maximum achievable performance is not only a function of the data sparsness but also of the per user rating distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Movielens 100k dataset\n",
    "\n",
    "Below we apply the above analysis on the movielens 100k dataset. The size of the dataset enhanches many of the features found above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating  timestamp\n",
       "0     196      242       3  881250949\n",
       "1     186      302       3  891717742\n",
       "2      22      377       1  878887116\n",
       "3     244       51       2  880606923\n",
       "4     166      346       1  886397596"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select Movielens data size: 100k\n",
    "MOVIELENS_DATA_SIZE = '100k'\n",
    "\n",
    "data = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=['userID','movieID','rating','timestamp']\n",
    ")\n",
    "\n",
    "# Convert to 32-bit in order to reduce memory consumption \n",
    "data.loc[:, 'rating'] = data['rating'].astype(np.int32) \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_rated_ml = data.rating.count()\n",
    "total_rated_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nusers= len(data.userID.unique())\n",
    "Nusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nitems= len(data.movieID.unique())\n",
    "Nitems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7836691410392365"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nitems/Nusers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. Random Splitter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data using the random split \n",
    "Ztr_random, Ztst_random = python_random_split(data, ratio = 0.75, seed= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42083</th>\n",
       "      <td>600</td>\n",
       "      <td>651</td>\n",
       "      <td>4</td>\n",
       "      <td>888451492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71825</th>\n",
       "      <td>607</td>\n",
       "      <td>494</td>\n",
       "      <td>5</td>\n",
       "      <td>883879556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99535</th>\n",
       "      <td>875</td>\n",
       "      <td>1103</td>\n",
       "      <td>5</td>\n",
       "      <td>876465144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47879</th>\n",
       "      <td>648</td>\n",
       "      <td>238</td>\n",
       "      <td>3</td>\n",
       "      <td>882213535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36734</th>\n",
       "      <td>113</td>\n",
       "      <td>273</td>\n",
       "      <td>4</td>\n",
       "      <td>875935609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userID  movieID  rating  timestamp\n",
       "42083     600      651       4  888451492\n",
       "71825     607      494       5  883879556\n",
       "99535     875     1103       5  876465144\n",
       "47879     648      238       3  882213535\n",
       "36734     113      273       4  875935609"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ztst_random.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global % of rated items in the train set 75.0\n",
      "global % of rated items in the test set 25.0\n"
     ]
    }
   ],
   "source": [
    "print( 'global % of rated items in the train set', (len(Ztr_random.rating)/total_rated_ml)*100 )\n",
    "print( 'global % of rated items in the test set', (len(Ztst_random.rating)/total_rated_ml)*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userID\n",
       "1      0.203\n",
       "2      0.045\n",
       "3      0.037\n",
       "4      0.018\n",
       "5      0.133\n",
       "6      0.161\n",
       "7      0.303\n",
       "8      0.046\n",
       "9      0.014\n",
       "10     0.148\n",
       "11     0.130\n",
       "12     0.039\n",
       "13     0.454\n",
       "14     0.077\n",
       "15     0.080\n",
       "16     0.111\n",
       "17     0.018\n",
       "18     0.197\n",
       "19     0.015\n",
       "20     0.036\n",
       "21     0.136\n",
       "22     0.096\n",
       "23     0.105\n",
       "24     0.055\n",
       "25     0.066\n",
       "26     0.085\n",
       "27     0.017\n",
       "28     0.058\n",
       "29     0.025\n",
       "30     0.027\n",
       "       ...  \n",
       "914    0.018\n",
       "915    0.017\n",
       "916    0.237\n",
       "917    0.022\n",
       "918    0.073\n",
       "919    0.163\n",
       "920    0.017\n",
       "921    0.078\n",
       "922    0.100\n",
       "923    0.058\n",
       "924    0.060\n",
       "925    0.023\n",
       "926    0.015\n",
       "927    0.086\n",
       "928    0.022\n",
       "929    0.035\n",
       "930    0.048\n",
       "931    0.047\n",
       "932    0.173\n",
       "933    0.129\n",
       "934    0.136\n",
       "935    0.033\n",
       "936    0.116\n",
       "937    0.031\n",
       "938    0.080\n",
       "939    0.045\n",
       "940    0.084\n",
       "941    0.019\n",
       "942    0.059\n",
       "943    0.126\n",
       "Name: rating, Length: 943, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user % of training example \n",
    "(Ztr_random.groupby(by= 'userID').rating.count()/total_rated_ml)*100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, most users get a % of training examples $\\ll 1$%. We can check this explictly by printing the % of users getting more than 1% of the training examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.738069989395548"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( ((Ztr_random.groupby(by= 'userID').rating.count()/total_rated_ml)*100  >= 0.1).sum()/Nusers )*100  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userID\n",
       "1      0.069\n",
       "2      0.017\n",
       "3      0.017\n",
       "4      0.006\n",
       "5      0.042\n",
       "6      0.050\n",
       "7      0.100\n",
       "8      0.013\n",
       "9      0.008\n",
       "10     0.036\n",
       "11     0.051\n",
       "12     0.012\n",
       "13     0.182\n",
       "14     0.021\n",
       "15     0.024\n",
       "16     0.029\n",
       "17     0.010\n",
       "18     0.080\n",
       "19     0.005\n",
       "20     0.012\n",
       "21     0.043\n",
       "22     0.032\n",
       "23     0.046\n",
       "24     0.013\n",
       "25     0.012\n",
       "26     0.022\n",
       "27     0.008\n",
       "28     0.021\n",
       "29     0.009\n",
       "30     0.016\n",
       "       ...  \n",
       "914    0.005\n",
       "915    0.009\n",
       "916    0.080\n",
       "917    0.013\n",
       "918    0.030\n",
       "919    0.054\n",
       "920    0.009\n",
       "921    0.032\n",
       "922    0.027\n",
       "923    0.016\n",
       "924    0.022\n",
       "925    0.009\n",
       "926    0.005\n",
       "927    0.034\n",
       "928    0.010\n",
       "929    0.014\n",
       "930    0.015\n",
       "931    0.014\n",
       "932    0.068\n",
       "933    0.055\n",
       "934    0.038\n",
       "935    0.006\n",
       "936    0.026\n",
       "937    0.009\n",
       "938    0.028\n",
       "939    0.004\n",
       "940    0.023\n",
       "941    0.003\n",
       "942    0.020\n",
       "943    0.042\n",
       "Name: rating, Length: 943, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user % of test example \n",
    "(Ztst_random.groupby(by= 'userID').rating.count()/total_rated_ml)*100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are interested in evaluating the effect of the splitter on the @k metrics with $k=10$, we can find the fraction of users in the test set having at least 10 test examples. As explained in the previous section, this also defines the maximum achievable precision of the recommender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7073170731707317"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( ( (Ztst_random.groupby(by= 'userID').rating.count() ) >= 10 ).sum()/Nusers )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The max precision @k can be evaluated using the functions defined in the previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8846235418875928"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zp_random = max_k(Ztst_random, k=10, group = 'userID')\n",
    "max_precision_at_k(Zp_random, k=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Python Stratified Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it took 3.073160 s to split the data\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#split data using the random split \n",
    "Ztr_strat, Ztst_strat = python_stratified_split(data, ratio = 0.75, seed= 123, col_user ='userID', col_item= 'itemID')\n",
    "elapsed_strat = time.time() - start\n",
    "print('it took %f s to split the data' %elapsed_strat )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15764</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>5</td>\n",
       "      <td>874965677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14792</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>878542845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8737</th>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "      <td>4</td>\n",
       "      <td>888732908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62069</th>\n",
       "      <td>1</td>\n",
       "      <td>191</td>\n",
       "      <td>5</td>\n",
       "      <td>875072956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25721</th>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>3</td>\n",
       "      <td>878542608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userID  movieID  rating  timestamp\n",
       "15764       1      196       5  874965677\n",
       "14792       1      103       1  878542845\n",
       "8737        1      209       4  888732908\n",
       "62069       1      191       5  875072956\n",
       "25721       1      141       3  878542608"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ztst_strat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global % of rated items in the train set 74.992\n",
      "global % of rated items in the test set 25.008000000000003\n"
     ]
    }
   ],
   "source": [
    "print( 'global % of rated items in the train set', (len(Ztr_strat.rating)/total_rated_ml)*100 )\n",
    "print( 'global % of rated items in the test set', (len(Ztst_strat.rating)/total_rated_ml)*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userID\n",
       "1      0.204\n",
       "2      0.046\n",
       "3      0.040\n",
       "4      0.018\n",
       "5      0.131\n",
       "6      0.158\n",
       "7      0.302\n",
       "8      0.044\n",
       "9      0.016\n",
       "10     0.138\n",
       "11     0.136\n",
       "12     0.038\n",
       "13     0.477\n",
       "14     0.074\n",
       "15     0.078\n",
       "16     0.105\n",
       "17     0.021\n",
       "18     0.208\n",
       "19     0.015\n",
       "20     0.036\n",
       "21     0.134\n",
       "22     0.096\n",
       "23     0.113\n",
       "24     0.051\n",
       "25     0.058\n",
       "26     0.080\n",
       "27     0.019\n",
       "28     0.059\n",
       "29     0.026\n",
       "30     0.032\n",
       "       ...  \n",
       "914    0.017\n",
       "915    0.020\n",
       "916    0.238\n",
       "917    0.026\n",
       "918    0.077\n",
       "919    0.163\n",
       "920    0.020\n",
       "921    0.082\n",
       "922    0.095\n",
       "923    0.056\n",
       "924    0.062\n",
       "925    0.024\n",
       "926    0.015\n",
       "927    0.090\n",
       "928    0.024\n",
       "929    0.037\n",
       "930    0.047\n",
       "931    0.046\n",
       "932    0.181\n",
       "933    0.138\n",
       "934    0.130\n",
       "935    0.029\n",
       "936    0.106\n",
       "937    0.030\n",
       "938    0.081\n",
       "939    0.037\n",
       "940    0.080\n",
       "941    0.016\n",
       "942    0.059\n",
       "943    0.126\n",
       "Name: rating, Length: 943, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user % of training example \n",
    "(Ztr_strat.groupby(by= 'userID').rating.count()/total_rated_ml)*100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the % of users getting more than 1% of the training examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.056203605514312"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( ((Ztr_strat.groupby(by= 'userID').rating.count()/total_rated_ml)*100  >= 0.1).sum()/Nusers )*100  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userID\n",
       "1      0.068\n",
       "2      0.016\n",
       "3      0.014\n",
       "4      0.006\n",
       "5      0.044\n",
       "6      0.053\n",
       "7      0.101\n",
       "8      0.015\n",
       "9      0.006\n",
       "10     0.046\n",
       "11     0.045\n",
       "12     0.013\n",
       "13     0.159\n",
       "14     0.024\n",
       "15     0.026\n",
       "16     0.035\n",
       "17     0.007\n",
       "18     0.069\n",
       "19     0.005\n",
       "20     0.012\n",
       "21     0.045\n",
       "22     0.032\n",
       "23     0.038\n",
       "24     0.017\n",
       "25     0.020\n",
       "26     0.027\n",
       "27     0.006\n",
       "28     0.020\n",
       "29     0.008\n",
       "30     0.011\n",
       "       ...  \n",
       "914    0.006\n",
       "915    0.006\n",
       "916    0.079\n",
       "917    0.009\n",
       "918    0.026\n",
       "919    0.054\n",
       "920    0.006\n",
       "921    0.028\n",
       "922    0.032\n",
       "923    0.018\n",
       "924    0.020\n",
       "925    0.008\n",
       "926    0.005\n",
       "927    0.030\n",
       "928    0.008\n",
       "929    0.012\n",
       "930    0.016\n",
       "931    0.015\n",
       "932    0.060\n",
       "933    0.046\n",
       "934    0.044\n",
       "935    0.010\n",
       "936    0.036\n",
       "937    0.010\n",
       "938    0.027\n",
       "939    0.012\n",
       "940    0.027\n",
       "941    0.006\n",
       "942    0.020\n",
       "943    0.042\n",
       "Name: rating, Length: 943, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user % of test example \n",
    "(Ztst_strat.groupby(by= 'userID').rating.count()/total_rated_ml)*100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " % of test examples $\\ge 1$%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8027571580063628"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( ((Ztst_strat.groupby(by= 'userID').rating.count()/total_rated_ml)*100  >= 0.1).sum()/Nusers )*100  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7020148462354189"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( ( (Ztst_strat.groupby(by= 'userID').rating.count() ) >= 10 ).sum()/Nusers )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8996818663838813"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zp_strat = max_k(Ztst_strat, k=10, group = 'userID')\n",
    "max_precision_at_k(Zp_strat, k=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Numpy stratified splitter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it took 0.028296 s to generate the affinity matrix\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#to use standard names across the analysis \n",
    "header = {\n",
    "        \"col_user\": \"userID\",\n",
    "        \"col_item\": \"movieID\",\n",
    "        \"col_rating\": \"rating\",\n",
    "    }\n",
    "\n",
    "#instantiate the splitter \n",
    "am = AffinityMatrix(DF = data, **header)\n",
    "\n",
    "#obtain the sparse matrix \n",
    "Z = am.gen_affinity_matrix()\n",
    "elapsed_am = time.time()- start\n",
    "print('it took %f s to generate the affinity matrix' %elapsed_am)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it took 0.080756 s to split the data\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "Ztr_np, Ztst_np = numpy_stratified_split(Z, ratio=0.75, seed=123)\n",
    "elapsed_np = time.time() - start \n",
    "print('it took %f s to split the data' %elapsed_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of rated elements in the train/test set \n",
    "Ztr_np_rated = np.sum(Ztr_np != 0, axis=1)  # number of rated items in the train set\n",
    "Ztst_np_rated = np.sum(Ztst_np != 0, axis=1)  # number of rated items in the test set\n",
    "\n",
    "#number of ratings per user\n",
    "Zrated = np.sum(Z != 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global % of rated items in the train set 74.992\n",
      "global % of rated items in the test set 25.008000000000003\n"
     ]
    }
   ],
   "source": [
    "print( 'global % of rated items in the train set', (Ztr_np_rated.sum() / total_rated_ml)*100 )\n",
    "print( 'global % of rated items in the test set', (Ztst_np_rated.sum() / total_rated_ml)*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75      , 0.74193548, 0.74074074, 0.75      , 0.74857143,\n",
       "       0.74881517, 0.74937965, 0.74576271, 0.72727273, 0.75      ,\n",
       "       0.75138122, 0.74509804, 0.75      , 0.75510204, 0.75      ,\n",
       "       0.75      , 0.75      , 0.75090253, 0.75      , 0.75      ,\n",
       "       0.74860335, 0.75      , 0.74834437, 0.75      , 0.74358974,\n",
       "       0.74766355, 0.76      , 0.74683544, 0.76470588, 0.74418605,\n",
       "       0.75      , 0.75609756, 0.75      , 0.75      , 0.76      ,\n",
       "       0.75      , 0.75438596, 0.75206612, 0.72727273, 0.74285714,\n",
       "       0.75      , 0.74863388, 0.75113122, 0.74834437, 0.75      ,\n",
       "       0.74074074, 0.76      , 0.75757576, 0.74883721, 0.75      ,\n",
       "       0.73913043, 0.75      , 0.75      , 0.75384615, 0.76190476,\n",
       "       0.7486631 , 0.75471698, 0.75324675, 0.7486911 , 0.75      ,\n",
       "       0.76190476, 0.75      , 0.75268817, 0.75      , 0.75      ,\n",
       "       0.73684211, 0.73333333, 0.76470588, 0.75384615, 0.7480916 ,\n",
       "       0.73684211, 0.75182482, 0.75757576, 0.74358974, 0.74683544,\n",
       "       0.75609756, 0.75      , 0.76190476, 0.74545455, 0.75862069,\n",
       "       0.75862069, 0.75      , 0.7483871 , 0.75      , 0.75      ,\n",
       "       0.73913043, 0.74881517, 0.76190476, 0.75      , 0.75      ,\n",
       "       0.75510204, 0.75      , 0.75      , 0.75      , 0.74820144,\n",
       "       0.75      , 0.74603175, 0.74074074, 0.75      , 0.74576271,\n",
       "       0.74626866, 0.75      , 0.75862069, 0.74774775, 0.73913043,\n",
       "       0.75      , 0.72727273, 0.75757576, 0.75213675, 0.7518797 ,\n",
       "       0.75      , 0.73913043, 0.74509804, 0.75      , 0.75      ,\n",
       "       0.74825175, 0.74418605, 0.74647887, 0.75138122, 0.76923077,\n",
       "       0.75675676, 0.75409836, 0.74074074, 0.75      , 0.74725275,\n",
       "       0.75555556, 0.73913043, 0.75      , 0.73333333, 0.75070822,\n",
       "       0.73333333, 0.72727273, 0.76923077, 0.76      , 0.74545455,\n",
       "       0.74285714, 0.74468085, 0.74509804, 0.75      , 0.76190476,\n",
       "       0.74766355, 0.75757576, 0.75      , 0.74757282, 0.75      ,\n",
       "       0.75862069, 0.75      , 0.75384615, 0.75      , 0.75      ,\n",
       "       0.74918567, 0.75471698, 0.73913043, 0.74509804, 0.72727273,\n",
       "       0.75675676, 0.74509804, 0.75144509, 0.74766355, 0.75      ,\n",
       "       0.75862069, 0.76190476, 0.73913043, 0.74603175, 0.73333333,\n",
       "       0.75      , 0.75362319, 0.75362319, 0.75675676, 0.72727273,\n",
       "       0.75      , 0.74074074, 0.74418605, 0.75141243, 0.73684211,\n",
       "       0.74603175, 0.74782609, 0.75091575, 0.76190476, 0.74603175,\n",
       "       0.74942529, 0.75      , 0.75471698, 0.74900398, 0.75      ,\n",
       "       0.75      , 0.75      , 0.75      , 0.7486631 , 0.74576271,\n",
       "       0.74074074, 0.74285714, 0.75206612, 0.75081967, 0.75      ,\n",
       "       0.74358974, 0.74576271, 0.75138122, 0.75      , 0.75      ,\n",
       "       0.75129534, 0.75      , 0.74418605, 0.76190476, 0.72727273,\n",
       "       0.75      , 0.74782609, 0.75757576, 0.75757576, 0.75      ,\n",
       "       0.75675676, 0.76      , 0.74603175, 0.75      , 0.75268817,\n",
       "       0.7480916 , 0.75      , 0.75471698, 0.75      , 0.72727273,\n",
       "       0.75342466, 0.74935401, 0.75238095, 0.75177305, 0.74074074,\n",
       "       0.76      , 0.75862069, 0.76190476, 0.73333333, 0.7518797 ,\n",
       "       0.76190476, 0.75268817, 0.74545455, 0.75      , 0.74468085,\n",
       "       0.75      , 0.75      , 0.75862069, 0.74842767, 0.75      ,\n",
       "       0.73913043, 0.75      , 0.75308642, 0.74789916, 0.72727273,\n",
       "       0.74871795, 0.76923077, 0.75      , 0.7515528 , 0.75409836,\n",
       "       0.75324675, 0.76190476, 0.75257732, 0.74842767, 0.74698795,\n",
       "       0.74879227, 0.75438596, 0.73913043, 0.73913043, 0.75      ,\n",
       "       0.74074074, 0.75      , 0.74796748, 0.75      , 0.73913043,\n",
       "       0.73913043, 0.75135135, 0.75      , 0.74922601, 0.75362319,\n",
       "       0.74820144, 0.74509804, 0.72727273, 0.74647887, 0.74736842,\n",
       "       0.74903475, 0.74074074, 0.73913043, 0.75115207, 0.75193798,\n",
       "       0.76923077, 0.72727273, 0.75471698, 0.74468085, 0.75      ,\n",
       "       0.75      , 0.74193548, 0.74666667, 0.74074074, 0.74666667,\n",
       "       0.75      , 0.75      , 0.75      , 0.74666667, 0.75      ,\n",
       "       0.74829932, 0.75      , 0.7480315 , 0.75      , 0.75      ,\n",
       "       0.74909091, 0.76190476, 0.75      , 0.76923077, 0.74774775,\n",
       "       0.75      , 0.75      , 0.75062972, 0.75      , 0.76190476,\n",
       "       0.74829932, 0.74887892, 0.7480916 , 0.75102041, 0.74712644,\n",
       "       0.74666667, 0.72727273, 0.74712644, 0.73913043, 0.75324675,\n",
       "       0.752     , 0.74509804, 0.75280899, 0.75757576, 0.74647887,\n",
       "       0.7486631 , 0.75      , 0.74911661, 0.75384615, 0.74829932,\n",
       "       0.74285714, 0.74863388, 0.76923077, 0.75075075, 0.72727273,\n",
       "       0.75384615, 0.76470588, 0.74666667, 0.7480315 , 0.75      ,\n",
       "       0.76190476, 0.75124378, 0.75105485, 0.74736842, 0.75      ,\n",
       "       0.75129534, 0.74874372, 0.75862069, 0.75609756, 0.76      ,\n",
       "       0.75      , 0.76190476, 0.76      , 0.75107296, 0.76923077,\n",
       "       0.75      , 0.75      , 0.74418605, 0.74074074, 0.74509804,\n",
       "       0.75206612, 0.76      , 0.74919614, 0.75      , 0.75862069,\n",
       "       0.75757576, 0.75862069, 0.75555556, 0.72727273, 0.74666667,\n",
       "       0.74509804, 0.75757576, 0.75107296, 0.75182482, 0.75      ,\n",
       "       0.73333333, 0.75757576, 0.74933333, 0.75      , 0.75308642,\n",
       "       0.7480315 , 0.75471698, 0.74647887, 0.72727273, 0.75088968,\n",
       "       0.73913043, 0.75      , 0.75      , 0.74907749, 0.74193548,\n",
       "       0.75206612, 0.74774775, 0.75      , 0.75167785, 0.75438596,\n",
       "       0.74074074, 0.74509804, 0.75      , 0.7492163 , 0.72727273,\n",
       "       0.75163399, 0.75      , 0.76      , 0.75      , 0.75033921,\n",
       "       0.74853801, 0.75221239, 0.74074074, 0.74876847, 0.75      ,\n",
       "       0.75862069, 0.74509804, 0.76      , 0.76      , 0.75      ,\n",
       "       0.7505071 , 0.75068493, 0.75      , 0.75      , 0.75      ,\n",
       "       0.74193548, 0.75257732, 0.75      , 0.75      , 0.75      ,\n",
       "       0.75247525, 0.74193548, 0.74545455, 0.74879227, 0.75384615,\n",
       "       0.76190476, 0.74193548, 0.75609756, 0.75      , 0.74934037,\n",
       "       0.75172414, 0.74904943, 0.75757576, 0.74193548, 0.74509804,\n",
       "       0.75      , 0.74825175, 0.75      , 0.75      , 0.74814815,\n",
       "       0.75      , 0.74820144, 0.73684211, 0.74666667, 0.75      ,\n",
       "       0.75510204, 0.74757282, 0.75      , 0.75      , 0.75132275,\n",
       "       0.75115207, 0.75090253, 0.74863388, 0.74576271, 0.75      ,\n",
       "       0.73913043, 0.75757576, 0.7518797 , 0.75471698, 0.75      ,\n",
       "       0.75247525, 0.75      , 0.74825175, 0.74418605, 0.75438596,\n",
       "       0.74193548, 0.74904943, 0.74285714, 0.74923547, 0.75      ,\n",
       "       0.74698795, 0.74285714, 0.75221239, 0.75247525, 0.75      ,\n",
       "       0.75      , 0.76923077, 0.74576271, 0.74820144, 0.76923077,\n",
       "       0.75132275, 0.74891775, 0.75324675, 0.75229358, 0.75438596,\n",
       "       0.75757576, 0.74545455, 0.74814815, 0.74468085, 0.75117371,\n",
       "       0.75193798, 0.74910394, 0.75167785, 0.74509804, 0.75111111,\n",
       "       0.75342466, 0.75675676, 0.75      , 0.74900398, 0.75      ,\n",
       "       0.75206612, 0.75862069, 0.74712644, 0.75757576, 0.73333333,\n",
       "       0.75      , 0.76190476, 0.72727273, 0.75257732, 0.75      ,\n",
       "       0.76190476, 0.75675676, 0.75342466, 0.75510204, 0.73913043,\n",
       "       0.74666667, 0.73333333, 0.75      , 0.75163399, 0.74074074,\n",
       "       0.75      , 0.75182482, 0.75471698, 0.74418605, 0.75555556,\n",
       "       0.73333333, 0.75182482, 0.75      , 0.75      , 0.75229358,\n",
       "       0.74846626, 0.75102041, 0.75308642, 0.75      , 0.74603175,\n",
       "       0.7518797 , 0.74814815, 0.75126904, 0.74193548, 0.75308642,\n",
       "       0.74576271, 0.73913043, 0.7483871 , 0.76      , 0.75      ,\n",
       "       0.74850299, 0.75      , 0.75      , 0.75438596, 0.75      ,\n",
       "       0.75      , 0.75471698, 0.75      , 0.75      , 0.75247525,\n",
       "       0.75070028, 0.75      , 0.73333333, 0.76470588, 0.74285714,\n",
       "       0.75167785, 0.7483871 , 0.75308642, 0.74285714, 0.72727273,\n",
       "       0.75      , 0.75      , 0.74509804, 0.73913043, 0.76923077,\n",
       "       0.75      , 0.75      , 0.75      , 0.75675676, 0.74468085,\n",
       "       0.75      , 0.74193548, 0.74074074, 0.75      , 0.75      ,\n",
       "       0.74698795, 0.75510204, 0.75111111, 0.74418605, 0.75      ,\n",
       "       0.75      , 0.75      , 0.75      , 0.76      , 0.75      ,\n",
       "       0.75      , 0.75609756, 0.76      , 0.74468085, 0.75280899,\n",
       "       0.75      , 0.75862069, 0.74468085, 0.74074074, 0.75555556,\n",
       "       0.75      , 0.75675676, 0.74846626, 0.75      , 0.74666667,\n",
       "       0.76190476, 0.74074074, 0.75      , 0.74358974, 0.74757282,\n",
       "       0.74418605, 0.75      , 0.75      , 0.75280899, 0.74545455,\n",
       "       0.74853801, 0.75      , 0.75555556, 0.75177305, 0.75471698,\n",
       "       0.75      , 0.75138122, 0.74074074, 0.75206612, 0.75      ,\n",
       "       0.75      , 0.74576271, 0.75862069, 0.74814815, 0.76470588,\n",
       "       0.75      , 0.75      , 0.74626866, 0.75      , 0.75229358,\n",
       "       0.75      , 0.74842767, 0.74757282, 0.76190476, 0.75409836,\n",
       "       0.73684211, 0.75862069, 0.75084175, 0.75      , 0.74919614,\n",
       "       0.76190476, 0.72727273, 0.74911661, 0.74829932, 0.75036496,\n",
       "       0.75      , 0.75862069, 0.74647887, 0.7486911 , 0.75      ,\n",
       "       0.75206612, 0.73913043, 0.74683544, 0.74698795, 0.74647887,\n",
       "       0.75102041, 0.74468085, 0.73913043, 0.75      , 0.73913043,\n",
       "       0.75      , 0.75862069, 0.74285714, 0.75609756, 0.76470588,\n",
       "       0.75324675, 0.75510204, 0.75      , 0.74193548, 0.73684211,\n",
       "       0.72727273, 0.74937343, 0.74666667, 0.74418605, 0.75      ,\n",
       "       0.74647887, 0.76190476, 0.75      , 0.75      , 0.74782609,\n",
       "       0.75      , 0.75      , 0.75324675, 0.75159236, 0.73684211,\n",
       "       0.75862069, 0.75238095, 0.7480315 , 0.75167785, 0.76190476,\n",
       "       0.75757576, 0.74193548, 0.74468085, 0.75555556, 0.75438596,\n",
       "       0.75862069, 0.75      , 0.75238095, 0.75362319, 0.74418605,\n",
       "       0.75113122, 0.75308642, 0.73333333, 0.75      , 0.74850299,\n",
       "       0.75092937, 0.75268817, 0.74358974, 0.74626866, 0.73333333,\n",
       "       0.75      , 0.76190476, 0.72727273, 0.75294118, 0.76      ,\n",
       "       0.75      , 0.7515528 , 0.76923077, 0.76190476, 0.73684211,\n",
       "       0.74698795, 0.75      , 0.74766355, 0.75      , 0.75471698,\n",
       "       0.75      , 0.75757576, 0.75      , 0.74285714, 0.75      ,\n",
       "       0.75      , 0.76923077, 0.74285714, 0.74074074, 0.75      ,\n",
       "       0.74626866, 0.75085324, 0.75      , 0.75081967, 0.75757576,\n",
       "       0.75      , 0.75342466, 0.75438596, 0.76470588, 0.73684211,\n",
       "       0.75229358, 0.74698795, 0.75070028, 0.75      , 0.75609756,\n",
       "       0.75757576, 0.76190476, 0.75193798, 0.75229358, 0.73913043,\n",
       "       0.74857143, 0.75675676, 0.75      , 0.75862069, 0.75      ,\n",
       "       0.74285714, 0.75757576, 0.7515528 , 0.75      , 0.75      ,\n",
       "       0.75238095, 0.75      , 0.75384615, 0.75675676, 0.74545455,\n",
       "       0.76190476, 0.75      , 0.73333333, 0.74358974, 0.74074074,\n",
       "       0.75213675, 0.75438596, 0.75100402, 0.75757576, 0.74891775,\n",
       "       0.76      , 0.74468085, 0.74545455, 0.74358974, 0.74842767,\n",
       "       0.74860335, 0.76923077, 0.74895397, 0.75      , 0.75      ,\n",
       "       0.76923077, 0.74666667, 0.75757576, 0.75      , 0.75091575,\n",
       "       0.75      , 0.75      , 0.73913043, 0.75      , 0.76923077,\n",
       "       0.76190476, 0.75      , 0.75862069, 0.74285714, 0.74863388,\n",
       "       0.76      , 0.75      , 0.76190476, 0.75      , 0.76190476,\n",
       "       0.74193548, 0.76      , 0.75135135, 0.75      , 0.75172414,\n",
       "       0.74782609, 0.75      , 0.75      , 0.75      , 0.75471698,\n",
       "       0.75342466, 0.76      , 0.74906367, 0.74074074, 0.74509804,\n",
       "       0.76      , 0.73913043, 0.75268817, 0.75438596, 0.75126904,\n",
       "       0.74193548, 0.74074074, 0.75      , 0.75308642, 0.74193548,\n",
       "       0.75061728, 0.75342466, 0.74666667, 0.73913043, 0.74509804,\n",
       "       0.75119617, 0.75510204, 0.75609756, 0.75115207, 0.73913043,\n",
       "       0.76923077, 0.72727273, 0.76190476, 0.74358974, 0.74647887,\n",
       "       0.74418605, 0.75151515, 0.74766355, 0.74829932, 0.75757576,\n",
       "       0.75      , 0.74736842, 0.75      , 0.74468085, 0.75092937,\n",
       "       0.74782609, 0.74647887, 0.75      , 0.76470588, 0.75280899,\n",
       "       0.76190476, 0.75308642, 0.74626866, 0.75862069, 0.75      ,\n",
       "       0.74903475, 0.75182482, 0.75      , 0.74418605, 0.74509804,\n",
       "       0.75      , 0.74853801, 0.75      , 0.74846626, 0.74789916,\n",
       "       0.74468085, 0.75221239, 0.74576271, 0.75102041, 0.75      ,\n",
       "       0.75138122, 0.75135135, 0.73333333, 0.74814815, 0.75555556,\n",
       "       0.75      , 0.75510204, 0.75      , 0.74468085, 0.75      ,\n",
       "       0.75609756, 0.74829932, 0.75675676, 0.76923077, 0.75      ,\n",
       "       0.75510204, 0.75471698, 0.75      , 0.73913043, 0.76923077,\n",
       "       0.75078864, 0.74285714, 0.74757282, 0.75115207, 0.76923077,\n",
       "       0.74545455, 0.7480315 , 0.75675676, 0.75609756, 0.75      ,\n",
       "       0.75      , 0.75      , 0.75      , 0.75510204, 0.74603175,\n",
       "       0.75409836, 0.75103734, 0.75      , 0.74712644, 0.74358974,\n",
       "       0.74647887, 0.75      , 0.75      , 0.75510204, 0.74766355,\n",
       "       0.72727273, 0.74683544, 0.75      ])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user percentage of training examples \n",
    "Ztr_np_rated/Zrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25      , 0.25806452, 0.25925926, 0.25      , 0.25142857,\n",
       "       0.25118483, 0.25062035, 0.25423729, 0.27272727, 0.25      ,\n",
       "       0.24861878, 0.25490196, 0.25      , 0.24489796, 0.25      ,\n",
       "       0.25      , 0.25      , 0.24909747, 0.25      , 0.25      ,\n",
       "       0.25139665, 0.25      , 0.25165563, 0.25      , 0.25641026,\n",
       "       0.25233645, 0.24      , 0.25316456, 0.23529412, 0.25581395,\n",
       "       0.25      , 0.24390244, 0.25      , 0.25      , 0.24      ,\n",
       "       0.25      , 0.24561404, 0.24793388, 0.27272727, 0.25714286,\n",
       "       0.25      , 0.25136612, 0.24886878, 0.25165563, 0.25      ,\n",
       "       0.25925926, 0.24      , 0.24242424, 0.25116279, 0.25      ,\n",
       "       0.26086957, 0.25      , 0.25      , 0.24615385, 0.23809524,\n",
       "       0.2513369 , 0.24528302, 0.24675325, 0.2513089 , 0.25      ,\n",
       "       0.23809524, 0.25      , 0.24731183, 0.25      , 0.25      ,\n",
       "       0.26315789, 0.26666667, 0.23529412, 0.24615385, 0.2519084 ,\n",
       "       0.26315789, 0.24817518, 0.24242424, 0.25641026, 0.25316456,\n",
       "       0.24390244, 0.25      , 0.23809524, 0.25454545, 0.24137931,\n",
       "       0.24137931, 0.25      , 0.2516129 , 0.25      , 0.25      ,\n",
       "       0.26086957, 0.25118483, 0.23809524, 0.25      , 0.25      ,\n",
       "       0.24489796, 0.25      , 0.25      , 0.25      , 0.25179856,\n",
       "       0.25      , 0.25396825, 0.25925926, 0.25      , 0.25423729,\n",
       "       0.25373134, 0.25      , 0.24137931, 0.25225225, 0.26086957,\n",
       "       0.25      , 0.27272727, 0.24242424, 0.24786325, 0.2481203 ,\n",
       "       0.25      , 0.26086957, 0.25490196, 0.25      , 0.25      ,\n",
       "       0.25174825, 0.25581395, 0.25352113, 0.24861878, 0.23076923,\n",
       "       0.24324324, 0.24590164, 0.25925926, 0.25      , 0.25274725,\n",
       "       0.24444444, 0.26086957, 0.25      , 0.26666667, 0.24929178,\n",
       "       0.26666667, 0.27272727, 0.23076923, 0.24      , 0.25454545,\n",
       "       0.25714286, 0.25531915, 0.25490196, 0.25      , 0.23809524,\n",
       "       0.25233645, 0.24242424, 0.25      , 0.25242718, 0.25      ,\n",
       "       0.24137931, 0.25      , 0.24615385, 0.25      , 0.25      ,\n",
       "       0.25081433, 0.24528302, 0.26086957, 0.25490196, 0.27272727,\n",
       "       0.24324324, 0.25490196, 0.24855491, 0.25233645, 0.25      ,\n",
       "       0.24137931, 0.23809524, 0.26086957, 0.25396825, 0.26666667,\n",
       "       0.25      , 0.24637681, 0.24637681, 0.24324324, 0.27272727,\n",
       "       0.25      , 0.25925926, 0.25581395, 0.24858757, 0.26315789,\n",
       "       0.25396825, 0.25217391, 0.24908425, 0.23809524, 0.25396825,\n",
       "       0.25057471, 0.25      , 0.24528302, 0.25099602, 0.25      ,\n",
       "       0.25      , 0.25      , 0.25      , 0.2513369 , 0.25423729,\n",
       "       0.25925926, 0.25714286, 0.24793388, 0.24918033, 0.25      ,\n",
       "       0.25641026, 0.25423729, 0.24861878, 0.25      , 0.25      ,\n",
       "       0.24870466, 0.25      , 0.25581395, 0.23809524, 0.27272727,\n",
       "       0.25      , 0.25217391, 0.24242424, 0.24242424, 0.25      ,\n",
       "       0.24324324, 0.24      , 0.25396825, 0.25      , 0.24731183,\n",
       "       0.2519084 , 0.25      , 0.24528302, 0.25      , 0.27272727,\n",
       "       0.24657534, 0.25064599, 0.24761905, 0.24822695, 0.25925926,\n",
       "       0.24      , 0.24137931, 0.23809524, 0.26666667, 0.2481203 ,\n",
       "       0.23809524, 0.24731183, 0.25454545, 0.25      , 0.25531915,\n",
       "       0.25      , 0.25      , 0.24137931, 0.25157233, 0.25      ,\n",
       "       0.26086957, 0.25      , 0.24691358, 0.25210084, 0.27272727,\n",
       "       0.25128205, 0.23076923, 0.25      , 0.2484472 , 0.24590164,\n",
       "       0.24675325, 0.23809524, 0.24742268, 0.25157233, 0.25301205,\n",
       "       0.25120773, 0.24561404, 0.26086957, 0.26086957, 0.25      ,\n",
       "       0.25925926, 0.25      , 0.25203252, 0.25      , 0.26086957,\n",
       "       0.26086957, 0.24864865, 0.25      , 0.25077399, 0.24637681,\n",
       "       0.25179856, 0.25490196, 0.27272727, 0.25352113, 0.25263158,\n",
       "       0.25096525, 0.25925926, 0.26086957, 0.24884793, 0.24806202,\n",
       "       0.23076923, 0.27272727, 0.24528302, 0.25531915, 0.25      ,\n",
       "       0.25      , 0.25806452, 0.25333333, 0.25925926, 0.25333333,\n",
       "       0.25      , 0.25      , 0.25      , 0.25333333, 0.25      ,\n",
       "       0.25170068, 0.25      , 0.2519685 , 0.25      , 0.25      ,\n",
       "       0.25090909, 0.23809524, 0.25      , 0.23076923, 0.25225225,\n",
       "       0.25      , 0.25      , 0.24937028, 0.25      , 0.23809524,\n",
       "       0.25170068, 0.25112108, 0.2519084 , 0.24897959, 0.25287356,\n",
       "       0.25333333, 0.27272727, 0.25287356, 0.26086957, 0.24675325,\n",
       "       0.248     , 0.25490196, 0.24719101, 0.24242424, 0.25352113,\n",
       "       0.2513369 , 0.25      , 0.25088339, 0.24615385, 0.25170068,\n",
       "       0.25714286, 0.25136612, 0.23076923, 0.24924925, 0.27272727,\n",
       "       0.24615385, 0.23529412, 0.25333333, 0.2519685 , 0.25      ,\n",
       "       0.23809524, 0.24875622, 0.24894515, 0.25263158, 0.25      ,\n",
       "       0.24870466, 0.25125628, 0.24137931, 0.24390244, 0.24      ,\n",
       "       0.25      , 0.23809524, 0.24      , 0.24892704, 0.23076923,\n",
       "       0.25      , 0.25      , 0.25581395, 0.25925926, 0.25490196,\n",
       "       0.24793388, 0.24      , 0.25080386, 0.25      , 0.24137931,\n",
       "       0.24242424, 0.24137931, 0.24444444, 0.27272727, 0.25333333,\n",
       "       0.25490196, 0.24242424, 0.24892704, 0.24817518, 0.25      ,\n",
       "       0.26666667, 0.24242424, 0.25066667, 0.25      , 0.24691358,\n",
       "       0.2519685 , 0.24528302, 0.25352113, 0.27272727, 0.24911032,\n",
       "       0.26086957, 0.25      , 0.25      , 0.25092251, 0.25806452,\n",
       "       0.24793388, 0.25225225, 0.25      , 0.24832215, 0.24561404,\n",
       "       0.25925926, 0.25490196, 0.25      , 0.2507837 , 0.27272727,\n",
       "       0.24836601, 0.25      , 0.24      , 0.25      , 0.24966079,\n",
       "       0.25146199, 0.24778761, 0.25925926, 0.25123153, 0.25      ,\n",
       "       0.24137931, 0.25490196, 0.24      , 0.24      , 0.25      ,\n",
       "       0.2494929 , 0.24931507, 0.25      , 0.25      , 0.25      ,\n",
       "       0.25806452, 0.24742268, 0.25      , 0.25      , 0.25      ,\n",
       "       0.24752475, 0.25806452, 0.25454545, 0.25120773, 0.24615385,\n",
       "       0.23809524, 0.25806452, 0.24390244, 0.25      , 0.25065963,\n",
       "       0.24827586, 0.25095057, 0.24242424, 0.25806452, 0.25490196,\n",
       "       0.25      , 0.25174825, 0.25      , 0.25      , 0.25185185,\n",
       "       0.25      , 0.25179856, 0.26315789, 0.25333333, 0.25      ,\n",
       "       0.24489796, 0.25242718, 0.25      , 0.25      , 0.24867725,\n",
       "       0.24884793, 0.24909747, 0.25136612, 0.25423729, 0.25      ,\n",
       "       0.26086957, 0.24242424, 0.2481203 , 0.24528302, 0.25      ,\n",
       "       0.24752475, 0.25      , 0.25174825, 0.25581395, 0.24561404,\n",
       "       0.25806452, 0.25095057, 0.25714286, 0.25076453, 0.25      ,\n",
       "       0.25301205, 0.25714286, 0.24778761, 0.24752475, 0.25      ,\n",
       "       0.25      , 0.23076923, 0.25423729, 0.25179856, 0.23076923,\n",
       "       0.24867725, 0.25108225, 0.24675325, 0.24770642, 0.24561404,\n",
       "       0.24242424, 0.25454545, 0.25185185, 0.25531915, 0.24882629,\n",
       "       0.24806202, 0.25089606, 0.24832215, 0.25490196, 0.24888889,\n",
       "       0.24657534, 0.24324324, 0.25      , 0.25099602, 0.25      ,\n",
       "       0.24793388, 0.24137931, 0.25287356, 0.24242424, 0.26666667,\n",
       "       0.25      , 0.23809524, 0.27272727, 0.24742268, 0.25      ,\n",
       "       0.23809524, 0.24324324, 0.24657534, 0.24489796, 0.26086957,\n",
       "       0.25333333, 0.26666667, 0.25      , 0.24836601, 0.25925926,\n",
       "       0.25      , 0.24817518, 0.24528302, 0.25581395, 0.24444444,\n",
       "       0.26666667, 0.24817518, 0.25      , 0.25      , 0.24770642,\n",
       "       0.25153374, 0.24897959, 0.24691358, 0.25      , 0.25396825,\n",
       "       0.2481203 , 0.25185185, 0.24873096, 0.25806452, 0.24691358,\n",
       "       0.25423729, 0.26086957, 0.2516129 , 0.24      , 0.25      ,\n",
       "       0.25149701, 0.25      , 0.25      , 0.24561404, 0.25      ,\n",
       "       0.25      , 0.24528302, 0.25      , 0.25      , 0.24752475,\n",
       "       0.24929972, 0.25      , 0.26666667, 0.23529412, 0.25714286,\n",
       "       0.24832215, 0.2516129 , 0.24691358, 0.25714286, 0.27272727,\n",
       "       0.25      , 0.25      , 0.25490196, 0.26086957, 0.23076923,\n",
       "       0.25      , 0.25      , 0.25      , 0.24324324, 0.25531915,\n",
       "       0.25      , 0.25806452, 0.25925926, 0.25      , 0.25      ,\n",
       "       0.25301205, 0.24489796, 0.24888889, 0.25581395, 0.25      ,\n",
       "       0.25      , 0.25      , 0.25      , 0.24      , 0.25      ,\n",
       "       0.25      , 0.24390244, 0.24      , 0.25531915, 0.24719101,\n",
       "       0.25      , 0.24137931, 0.25531915, 0.25925926, 0.24444444,\n",
       "       0.25      , 0.24324324, 0.25153374, 0.25      , 0.25333333,\n",
       "       0.23809524, 0.25925926, 0.25      , 0.25641026, 0.25242718,\n",
       "       0.25581395, 0.25      , 0.25      , 0.24719101, 0.25454545,\n",
       "       0.25146199, 0.25      , 0.24444444, 0.24822695, 0.24528302,\n",
       "       0.25      , 0.24861878, 0.25925926, 0.24793388, 0.25      ,\n",
       "       0.25      , 0.25423729, 0.24137931, 0.25185185, 0.23529412,\n",
       "       0.25      , 0.25      , 0.25373134, 0.25      , 0.24770642,\n",
       "       0.25      , 0.25157233, 0.25242718, 0.23809524, 0.24590164,\n",
       "       0.26315789, 0.24137931, 0.24915825, 0.25      , 0.25080386,\n",
       "       0.23809524, 0.27272727, 0.25088339, 0.25170068, 0.24963504,\n",
       "       0.25      , 0.24137931, 0.25352113, 0.2513089 , 0.25      ,\n",
       "       0.24793388, 0.26086957, 0.25316456, 0.25301205, 0.25352113,\n",
       "       0.24897959, 0.25531915, 0.26086957, 0.25      , 0.26086957,\n",
       "       0.25      , 0.24137931, 0.25714286, 0.24390244, 0.23529412,\n",
       "       0.24675325, 0.24489796, 0.25      , 0.25806452, 0.26315789,\n",
       "       0.27272727, 0.25062657, 0.25333333, 0.25581395, 0.25      ,\n",
       "       0.25352113, 0.23809524, 0.25      , 0.25      , 0.25217391,\n",
       "       0.25      , 0.25      , 0.24675325, 0.24840764, 0.26315789,\n",
       "       0.24137931, 0.24761905, 0.2519685 , 0.24832215, 0.23809524,\n",
       "       0.24242424, 0.25806452, 0.25531915, 0.24444444, 0.24561404,\n",
       "       0.24137931, 0.25      , 0.24761905, 0.24637681, 0.25581395,\n",
       "       0.24886878, 0.24691358, 0.26666667, 0.25      , 0.25149701,\n",
       "       0.24907063, 0.24731183, 0.25641026, 0.25373134, 0.26666667,\n",
       "       0.25      , 0.23809524, 0.27272727, 0.24705882, 0.24      ,\n",
       "       0.25      , 0.2484472 , 0.23076923, 0.23809524, 0.26315789,\n",
       "       0.25301205, 0.25      , 0.25233645, 0.25      , 0.24528302,\n",
       "       0.25      , 0.24242424, 0.25      , 0.25714286, 0.25      ,\n",
       "       0.25      , 0.23076923, 0.25714286, 0.25925926, 0.25      ,\n",
       "       0.25373134, 0.24914676, 0.25      , 0.24918033, 0.24242424,\n",
       "       0.25      , 0.24657534, 0.24561404, 0.23529412, 0.26315789,\n",
       "       0.24770642, 0.25301205, 0.24929972, 0.25      , 0.24390244,\n",
       "       0.24242424, 0.23809524, 0.24806202, 0.24770642, 0.26086957,\n",
       "       0.25142857, 0.24324324, 0.25      , 0.24137931, 0.25      ,\n",
       "       0.25714286, 0.24242424, 0.2484472 , 0.25      , 0.25      ,\n",
       "       0.24761905, 0.25      , 0.24615385, 0.24324324, 0.25454545,\n",
       "       0.23809524, 0.25      , 0.26666667, 0.25641026, 0.25925926,\n",
       "       0.24786325, 0.24561404, 0.24899598, 0.24242424, 0.25108225,\n",
       "       0.24      , 0.25531915, 0.25454545, 0.25641026, 0.25157233,\n",
       "       0.25139665, 0.23076923, 0.25104603, 0.25      , 0.25      ,\n",
       "       0.23076923, 0.25333333, 0.24242424, 0.25      , 0.24908425,\n",
       "       0.25      , 0.25      , 0.26086957, 0.25      , 0.23076923,\n",
       "       0.23809524, 0.25      , 0.24137931, 0.25714286, 0.25136612,\n",
       "       0.24      , 0.25      , 0.23809524, 0.25      , 0.23809524,\n",
       "       0.25806452, 0.24      , 0.24864865, 0.25      , 0.24827586,\n",
       "       0.25217391, 0.25      , 0.25      , 0.25      , 0.24528302,\n",
       "       0.24657534, 0.24      , 0.25093633, 0.25925926, 0.25490196,\n",
       "       0.24      , 0.26086957, 0.24731183, 0.24561404, 0.24873096,\n",
       "       0.25806452, 0.25925926, 0.25      , 0.24691358, 0.25806452,\n",
       "       0.24938272, 0.24657534, 0.25333333, 0.26086957, 0.25490196,\n",
       "       0.24880383, 0.24489796, 0.24390244, 0.24884793, 0.26086957,\n",
       "       0.23076923, 0.27272727, 0.23809524, 0.25641026, 0.25352113,\n",
       "       0.25581395, 0.24848485, 0.25233645, 0.25170068, 0.24242424,\n",
       "       0.25      , 0.25263158, 0.25      , 0.25531915, 0.24907063,\n",
       "       0.25217391, 0.25352113, 0.25      , 0.23529412, 0.24719101,\n",
       "       0.23809524, 0.24691358, 0.25373134, 0.24137931, 0.25      ,\n",
       "       0.25096525, 0.24817518, 0.25      , 0.25581395, 0.25490196,\n",
       "       0.25      , 0.25146199, 0.25      , 0.25153374, 0.25210084,\n",
       "       0.25531915, 0.24778761, 0.25423729, 0.24897959, 0.25      ,\n",
       "       0.24861878, 0.24864865, 0.26666667, 0.25185185, 0.24444444,\n",
       "       0.25      , 0.24489796, 0.25      , 0.25531915, 0.25      ,\n",
       "       0.24390244, 0.25170068, 0.24324324, 0.23076923, 0.25      ,\n",
       "       0.24489796, 0.24528302, 0.25      , 0.26086957, 0.23076923,\n",
       "       0.24921136, 0.25714286, 0.25242718, 0.24884793, 0.23076923,\n",
       "       0.25454545, 0.2519685 , 0.24324324, 0.24390244, 0.25      ,\n",
       "       0.25      , 0.25      , 0.25      , 0.24489796, 0.25396825,\n",
       "       0.24590164, 0.24896266, 0.25      , 0.25287356, 0.25641026,\n",
       "       0.25352113, 0.25      , 0.25      , 0.24489796, 0.25233645,\n",
       "       0.27272727, 0.25316456, 0.25      ])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#per user percentage of test examples \n",
    "Ztst_np_rated/Zrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7020148462354189"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Ztst_np_rated >=10).sum()/Nusers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_precision at k=10, 0.8996818663838813\n"
     ]
    }
   ],
   "source": [
    "Z_top_np = return_top_k(Ztst_np, k=10)\n",
    "#evaluate the maximum achievable prediction \n",
    "Znum_pred_np = np.sum(Z_top_np !=0, axis=1)\n",
    "print('max_precision at k=10,', max_precision_at_k(Znum_pred_np, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, the stratifed splitters achieve a higher maximum achievable precision. On the other hand, the python stratified splitter is almost two order of magnitude slower than the python splitter.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Movielens 1m dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating  timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select Movielens data size: 100k\n",
    "MOVIELENS_DATA_SIZE = '1m'\n",
    "\n",
    "data1m = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=['userID','movieID','rating','timestamp']\n",
    ")\n",
    "\n",
    "# Convert to 32-bit in order to reduce memory consumption \n",
    "data1m.loc[:, 'rating'] = data1m['rating'].astype(np.int32) \n",
    "\n",
    "data1m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Python Random splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data using the random split \n",
    "Ytr_random, Ytst_random = python_random_split(data1m, ratio = 0.75, seed= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yp_random = max_k(Ytst_random, k=10, group = 'userID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9251366120218578"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_precision_at_k(Yp_random, k=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Python stratified splitter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "Atr_strat, Atst_strat = python_stratified_split(data1m, ratio = 0.75, seed= 123, col_user ='userID', col_item= 'itemID')\n",
    "elapsed_strat = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it took 89.691625 s to split the data\n"
     ]
    }
   ],
   "source": [
    "print( 'it took %f s to split the data' %elapsed_strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9386258278145694"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ap_tst = max_k(Atst_strat, k=10, group = 'userID')\n",
    "max_precision_at_k(Ap_tst, k=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Numpy stratified splitter  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "#to use standard names across the analysis \n",
    "header = {\n",
    "        \"col_user\": \"userID\",\n",
    "        \"col_item\": \"movieID\",\n",
    "        \"col_rating\": \"rating\",\n",
    "    }\n",
    "\n",
    "#instantiate the splitter \n",
    "am1m = AffinityMatrix(DF = data1m, **header)\n",
    "\n",
    "#obtain the sparse matrix \n",
    "A = am1m.gen_affinity_matrix()\n",
    "elapsed_affinity = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it took 0.223092 s to generate the afifnity matrix\n"
     ]
    }
   ],
   "source": [
    "print('it took %f s to generate the afifnity matrix' %elapsed_affinity )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "Atr_np, Atst_np = numpy_stratified_split(A, ratio=0.75, seed=123)\n",
    "elapsed_np = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it took 0.641507 s to split the data\n"
     ]
    }
   ],
   "source": [
    "print('it took %f s to split the data' %elapsed_np )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_precision at k=10, 0.9386258278145694\n"
     ]
    }
   ],
   "source": [
    "A_top_np = return_top_k(Atst_np, k=10)\n",
    "Anum_pred_np = np.sum(A_top_np !=0, axis=1)\n",
    "print('max_precision at k=10,', max_precision_at_k(Anum_pred_np, 10))"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
