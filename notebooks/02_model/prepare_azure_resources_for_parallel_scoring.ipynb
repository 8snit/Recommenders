{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Azure Resources \n",
    "\n",
    "The goal of this notebook is to create appropriate azure resources so that one can run the collection of SAR parallel scoring notebooks efficiently.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "This uses `azure-cli` to do some of the steps to create Azure Resources.\n",
    "\n",
    "\n",
    "## Credits\n",
    "\n",
    "This noteboook draws heavily from prior work on batch scoring using AML Pipelines: https://github.com/Microsoft/AMLBatchScoringPipeline/blob/master/01_create_resources.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amlpipeline_configuration_filename = 'pipeline_config_programmatic.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subscription & resource group\n",
    "SUBSCRIPTION_ID = os.getenv(\"AZ_SUB\",\"\")\n",
    "RESOURCE_GROUP = \"jeremr-parallelscore-auto\"\n",
    "LOCATION = \"eastus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# LOGIN IF NECESSARY\n",
    "list=`az account list -o table`\n",
    "if [ \"$list\" == '[]' ]; then\n",
    "  echo \"*** LOGGING INTO AZURE...\"\n",
    "  LOGIN_OUTPUT=$(az login -o table)\n",
    "else\n",
    "  echo \"*** Already logged in to Azure.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set appropriate subscription\n",
    "!az account set -s {SUBSCRIPTION_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the resource group\n",
    "!az group create -l {LOCATION} -n {RESOURCE_GROUP}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AML workspace and compute target\n",
    "AML_WORKSPACE = (\"{}ws\".format(RESOURCE_GROUP)).replace('_','-')\n",
    "AML_COMPUTE_NAME = (\"{}cmpt\".format(RESOURCE_GROUP)).replace('_','-')[0:16] # limit to 16 chars\n",
    "AML_VM_SIZE = \"Standard_D2\"\n",
    "AML_MIN_NODES = 4\n",
    "AML_MAX_NODES = 4\n",
    "AML_CONFIG_PATH = \"prog_aml\"\n",
    "\n",
    "# Scoring script\n",
    "CONDA_PACKAGES = [\"fastparquet\"]\n",
    "PIP_PACKAGES = [\"dask>=0.17.1\", \"pandas>=0.23.4\", \"numpy>=1.13.3\", \"scipy>=1.0.0\", \"toolz\", \"cloudpickle\"]\n",
    "PYTHON_VERSION = \"3.6.7\"\n",
    "PYTHON_SCRIPT_NAME = \"score.py\"\n",
    "PYTHON_SCRIPT_DIRECTORY = \"scripts\"\n",
    "\n",
    "## blobs were already created and had data uploaded to them via a similar script\n",
    "## e.g.\n",
    "## for fn in $(ls ratings_10m.parquet/*); do echo $fn; az storage blob upload -f $fn -c inputs -n $fn --account-name jrrecostorage;  done\n",
    "##  az storage blob upload -f sar_model_10m_fit0.pkl -c models -n sar_model_10m_fit0.pkl --account-name jrrecostorage\n",
    " \n",
    "STORAGE_ACCOUNT = \"{}storage\".format(RESOURCE_GROUP).replace('-','').replace('_','')[0:24]\n",
    "INPUTS_CONTAINER = \"inputs\"\n",
    "MODELS_CONTAINER = \"models\"\n",
    "OUTPUTS_CONTAINER = \"outputs\"\n",
    "print(STORAGE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Blob storage account\n",
    "!az storage account create -n {STORAGE_ACCOUNT} -g {RESOURCE_GROUP} -l {LOCATION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get blob keys\n",
    "tmp_blob_info = !az storage account keys list -g {RESOURCE_GROUP} -n {STORAGE_ACCOUNT}\n",
    "blob_key = json.loads(''.join(tmp_blob_info))[0]['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models, predictions and data containers\n",
    "!az storage container create -n {INPUTS_CONTAINER} --account-key {blob_key} --account-name {STORAGE_ACCOUNT}\n",
    "!az storage container create -n {MODELS_CONTAINER} --account-key {blob_key} --account-name {STORAGE_ACCOUNT}\n",
    "!az storage container create -n {OUTPUTS_CONTAINER} --account-key {blob_key} --account-name {STORAGE_ACCOUNT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AML Workspace\n",
    "aml_ws = Workspace.create(\n",
    "    name=AML_WORKSPACE,\n",
    "    subscription_id=SUBSCRIPTION_ID,\n",
    "    resource_group=RESOURCE_GROUP,\n",
    "    create_resource_group=False,\n",
    "    location=LOCATION,\n",
    "    exist_ok=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(AML_CONFIG_PATH)\n",
    "aml_ws.write_config(AML_CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create compute target\n",
    "provisioning_config = AmlCompute.provisioning_configuration(vm_size = AML_VM_SIZE,\n",
    "                                                            min_nodes = AML_MIN_NODES,\n",
    "                                                            max_nodes = AML_MAX_NODES)\n",
    "\n",
    "compute_target = ComputeTarget.create(aml_ws, AML_COMPUTE_NAME, provisioning_config)\n",
    "compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and get service principal credentials\n",
    "# couldn't install jq, so done manually\n",
    "temp = !az ad sp create-for-rbac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter out WARNING MESSAGES\n",
    "sp_info=json.loads(''.join([k for k in temp if not 'WARNING' in k]))\n",
    "sp_client = sp_info['appId']\n",
    "sp_secret = sp_info['password']\n",
    "tenant_id = sp_info['tenant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = {\n",
    "  \"sp_tenant\": tenant_id,\n",
    "  \"sp_client\": sp_client,\n",
    "  \"sp_secret\": sp_secret,\n",
    "  \"resource_group_name\": RESOURCE_GROUP,\n",
    "  \"subscription_id\": SUBSCRIPTION_ID,\n",
    "  \"aml_work_space\": AML_WORKSPACE,\n",
    "  \"experiment_name\": \"mm_score\",\n",
    "  \"cluster_name\": AML_COMPUTE_NAME,\n",
    "  \"location\": LOCATION,\n",
    "  \"blob_account\": STORAGE_ACCOUNT,\n",
    "  \"blob_key\": blob_key,\n",
    "  \"models_blob_container\": MODELS_CONTAINER,\n",
    "  \"data_blob_container\": INPUTS_CONTAINER,\n",
    "  \"preds_blob_container\": OUTPUTS_CONTAINER,\n",
    "  \"conda_packages\": CONDA_PACKAGES,\n",
    "  \"pip_packages\": PIP_PACKAGES,\n",
    "  \"python_version\": PYTHON_VERSION,\n",
    "  \"python_script_name\": PYTHON_SCRIPT_NAME,\n",
    "  \"python_script_directory\": PYTHON_SCRIPT_DIRECTORY\n",
    "}\n",
    "with open(amlpipeline_configuration_filename, 'w') as f:\n",
    "    json.dump(pipeline_config, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (recommenders)",
   "language": "python",
   "name": "recommenders"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
