{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "The goal of this notebook is to create appropriate azure resources so that one can run the collection of SAR parallel scoring notebooks easily.\n",
    "\n",
    "The order of the execution of these notebooks should be:\n",
    "\n",
    "- [parallel_scoring_0_prepare_azure_resources](parallel_scoring_0_prepare_azure_resources.ipynb) **(This notebook)**: This creates the azure resources used in other notebooks.\n",
    "- [parallel_scoring_1_prepare_data_and_model](parallel_scoring_1_prepare_data_and_model.ipynb): This uploads ratings data and an example model to Azure where agents can see them.\n",
    "- [parallel_scoring_2_prepare_and_run_amlpipeline](parallel_scoring_2_prepare_and_run_amlpipeline.ipynb): This creates and executes a parallel pipeline that leverages the resources and files created in prior steps.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "This uses `azure-cli` to do some of the steps to create Azure Resources.\n",
    "\n",
    "\n",
    "## Credits\n",
    "\n",
    "This noteboook draws heavily from prior work on batch scoring using AML Pipelines: https://github.com/Microsoft/AMLBatchScoringPipeline/blob/master/01_create_resources.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## name of the configuration file we'll create at the end\n",
    "amlpipeline_configuration_filename = 'pipeline_config_programmatic.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import modules\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify subscription & resource group\n",
    "SUBSCRIPTION_ID = os.getenv(\"AZ_SUB\",\"\")\n",
    "RESOURCE_GROUP = \"\"\n",
    "LOCATION = \"eastus\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure you are logged into Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# LOGIN IF NECESSARY\n",
    "list=`az account list -o table`\n",
    "if [ \"$list\" == '[]' ]; then\n",
    "  echo \"*** LOGGING INTO AZURE...\"\n",
    "  LOGIN_OUTPUT=$(az login -o table)\n",
    "else\n",
    "  echo \"*** Already logged in to Azure.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set appropriate subscription\n",
    "!az account set -s {SUBSCRIPTION_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the resource group\n",
    "!az group create -l {LOCATION} -n {RESOURCE_GROUP}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Configuration for Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AML workspace and compute target\n",
    "AML_WORKSPACE = (\"{}ws\".format(RESOURCE_GROUP)).replace('_','-')\n",
    "AML_COMPUTE_NAME = (\"{}cmpt\".format(RESOURCE_GROUP)).replace('_','-')[0:16] # limit to 16 chars\n",
    "AML_VM_SIZE = \"Standard_D2\"\n",
    "AML_MIN_NODES = 4\n",
    "AML_MAX_NODES = 4\n",
    "\n",
    "# Scoring script\n",
    "CONDA_PACKAGES = [\"fastparquet\"]\n",
    "PIP_PACKAGES = [\"dask>=0.17.1\", \"pandas>=0.23.4\", \"numpy>=1.13.3\", \"scipy>=1.0.0\", \"toolz\", \"cloudpickle\"]\n",
    "PYTHON_VERSION = \"3.6.7\"\n",
    "PYTHON_SCRIPT_NAME = \"score.py\"\n",
    "PYTHON_SCRIPT_DIRECTORY = \"scripts\"\n",
    "\n",
    "# storage information\n",
    "STORAGE_ACCOUNT = \"{}storage\".format(RESOURCE_GROUP).replace('-','').replace('_','')[0:24]\n",
    "INPUTS_CONTAINER = \"inputs\"\n",
    "MODELS_CONTAINER = \"models\"\n",
    "OUTPUTS_CONTAINER = \"outputs\"\n",
    "print(STORAGE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Blob storage account\n",
    "!az storage account create -n {STORAGE_ACCOUNT} -g {RESOURCE_GROUP} -l {LOCATION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get blob keys\n",
    "tmp_blob_info = !az storage account keys list -g {RESOURCE_GROUP} -n {STORAGE_ACCOUNT}\n",
    "blob_key = json.loads(''.join(tmp_blob_info))[0]['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models, predictions and data containers\n",
    "!az storage container create -n {INPUTS_CONTAINER} --account-key {blob_key} --account-name {STORAGE_ACCOUNT}\n",
    "!az storage container create -n {MODELS_CONTAINER} --account-key {blob_key} --account-name {STORAGE_ACCOUNT}\n",
    "!az storage container create -n {OUTPUTS_CONTAINER} --account-key {blob_key} --account-name {STORAGE_ACCOUNT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AML Workspace\n",
    "aml_ws = Workspace.create(\n",
    "    name=AML_WORKSPACE,\n",
    "    subscription_id=SUBSCRIPTION_ID,\n",
    "    resource_group=RESOURCE_GROUP,\n",
    "    create_resource_group=False,\n",
    "    location=LOCATION,\n",
    "    exist_ok=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create compute target\n",
    "provisioning_config = AmlCompute.provisioning_configuration(vm_size = AML_VM_SIZE,\n",
    "                                                            min_nodes = AML_MIN_NODES,\n",
    "                                                            max_nodes = AML_MAX_NODES)\n",
    "\n",
    "compute_target = ComputeTarget.create(aml_ws, AML_COMPUTE_NAME, provisioning_config)\n",
    "compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and get service principal credentials\n",
    "# couldn't install jq, so done manually\n",
    "temp = !az ad sp create-for-rbac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter out WARNING MESSAGES\n",
    "sp_info=json.loads(''.join([k for k in temp if not 'WARNING' in k]))\n",
    "sp_client = sp_info['appId']\n",
    "sp_secret = sp_info['password']\n",
    "tenant_id = sp_info['tenant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = {\n",
    "  \"sp_tenant\": tenant_id,\n",
    "  \"sp_client\": sp_client,\n",
    "  \"sp_secret\": sp_secret,\n",
    "  \"resource_group_name\": RESOURCE_GROUP,\n",
    "  \"subscription_id\": SUBSCRIPTION_ID,\n",
    "  \"aml_work_space\": AML_WORKSPACE,\n",
    "  \"experiment_name\": \"mm_score\",\n",
    "  \"cluster_name\": AML_COMPUTE_NAME,\n",
    "  \"location\": LOCATION,\n",
    "  \"blob_account\": STORAGE_ACCOUNT,\n",
    "  \"blob_key\": blob_key,\n",
    "  \"models_blob_container\": MODELS_CONTAINER,\n",
    "  \"data_blob_container\": INPUTS_CONTAINER,\n",
    "  \"preds_blob_container\": OUTPUTS_CONTAINER,\n",
    "  \"conda_packages\": CONDA_PACKAGES,\n",
    "  \"pip_packages\": PIP_PACKAGES,\n",
    "  \"python_version\": PYTHON_VERSION,\n",
    "  \"python_script_name\": PYTHON_SCRIPT_NAME,\n",
    "  \"python_script_directory\": PYTHON_SCRIPT_DIRECTORY\n",
    "}\n",
    "with open(amlpipeline_configuration_filename, 'w') as f:\n",
    "    json.dump(pipeline_config, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue...\n",
    "\n",
    "At this point, you have set up the Azure resources. Now you need to populate those Azure resources with files that you need in order to execute in parallel. To see that, please continue to the `prepare_data_and_model` noatebook [here](parallel_scoring_1_prepare_data_and_model.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (recommenders)",
   "language": "python",
   "name": "recommenders"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
